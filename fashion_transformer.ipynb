{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pypi.douban.com/simple/\n",
      "Collecting sklearn\n",
      "  Downloading http://pypi.doubanio.com/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "\u001b[?25l  Downloading http://pypi.doubanio.com/packages/0d/3a/b92670f5c368c20329ecc4c255993fae7934564d485c3ed7ea7b8da7f741/scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.4MB 74.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.13.3 in /opt/conda/envs/py3/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/envs/py3/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.15.4)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/db/03/c6/c0a7266e6b57a706217261ca0b713562ae529f0f629bd9266b\n",
      "Successfully built sklearn\n",
      "Installing collected packages: scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-0.20.2 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!/opt/conda/envs/py3/bin/pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!/opt/conda/envs/py3/bin/python3 -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/opennmt-models/iwslt.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!export PYTHONPATH=/data/wuwm/py-packages:${PYTHONPATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder and Decoder Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)    \n",
    "    \n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "    \n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position-wise Feed-Forward Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings and Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        \n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask\n",
    "    \n",
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        # print('src:', batch.src.is_cuda, 'trg:', batch.trg.is_cuda, 'src_mask:',\n",
    "        #                    batch.src_mask.is_cuda, 'trg_mask:', batch.trg_mask.is_cuda)\n",
    "    \n",
    "        out = model.forward(batch.src, batch.trg, \n",
    "                            batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens\n",
    "\n",
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)\n",
    "\n",
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))\n",
    "    \n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple copy task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_gen(V, batch, nbatches):\n",
    "    \"Generate random data for a src-tgt copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size=(batch, 10)))\n",
    "        data[:, 0] = 1\n",
    "        src = Variable(data, requires_grad=False)\n",
    "        tgt = Variable(data, requires_grad=False)\n",
    "        yield Batch(src, tgt, 0)\n",
    "        \n",
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        # return loss.data[0] * norm\n",
    "        return loss.data * norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the simple copy task.\n",
    "V = 11\n",
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "model = make_model(V, V, N=2)\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    run_epoch(data_gen(V, 30, 20), model, \n",
    "              SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "    model.eval()\n",
    "    print(run_epoch(data_gen(V, 30, 5), model, \n",
    "                    SimpleLossCompute(model.generator, criterion, None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]) )\n",
    "src = src.cuda()\n",
    "src_mask = Variable(torch.ones(1, 1, 10) )\n",
    "src_mask = src_mask.cuda()\n",
    "print(greedy_decode(model, src, src_mask, max_len=10, start_symbol=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fashion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.\n",
      "Warning:  apex was installed without --cuda_ext. Fused syncbn kernels will be unavailable.  Python fallbacks will be used instead.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedAdam will be unavailable.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedLayerNorm will be unavailable.\n",
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "# For data loading.\n",
    "from torchtext import data, datasets\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "if True:\n",
    "    # Load pre-trained model tokenizer (vocabulary)\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained('/notebooks/xff/data preprocessing/bert-base-chinese')\n",
    "    def tokenize_bert(text):\n",
    "        return bert_tokenizer.tokenize(text)\n",
    "    BOS_WORD = '<s>'\n",
    "    EOS_WORD = '</s>'\n",
    "    BLANK_WORD = \"<blank>\"\n",
    "    SRC = data.Field(tokenize=tokenize_bert, pad_token=BLANK_WORD)\n",
    "    TGT = data.Field(tokenize=tokenize_bert, init_token = BOS_WORD, \n",
    "                     eos_token = EOS_WORD, pad_token=BLANK_WORD)    \n",
    "    MAX_LEN = 100\n",
    "    train, val, test = data.TabularDataset.splits(\n",
    "        path='women_data', format='csv', train='women_train.csv',\n",
    "        validation='women_dev.csv', test='women_test.csv',\n",
    "        fields=[('category', None), ('src', SRC), ('trg', TGT)], skip_header=True, \n",
    "    filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "            len(vars(x)['trg']) <= MAX_LEN)    \n",
    "    MIN_FREQ = 2\n",
    "    SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "    TGT.build_vocab(train.trg, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyIterator(data.Iterator):\n",
    "    def create_batches(self):\n",
    "        if self.train:\n",
    "            def pool(d, random_shuffler):\n",
    "                for p in data.batch(d, self.batch_size * 100):\n",
    "                    p_batch = data.batch(\n",
    "                        sorted(p, key=self.sort_key),\n",
    "                        self.batch_size, self.batch_size_fn)\n",
    "                    for b in random_shuffler(list(p_batch)):\n",
    "                        yield b\n",
    "            self.batches = pool(self.data(), self.random_shuffler)\n",
    "            \n",
    "        else:\n",
    "            self.batches = []\n",
    "            for b in data.batch(self.data(), self.batch_size,\n",
    "                                          self.batch_size_fn):\n",
    "                self.batches.append(sorted(b, key=self.sort_key))\n",
    "\n",
    "def rebatch(pad_idx, batch):\n",
    "    \"Fix order in torchtext to match ours\"\n",
    "    src, trg = batch.src.transpose(0, 1), batch.trg.transpose(0, 1)\n",
    "    src = src.cuda()\n",
    "    trg = trg.cuda()\n",
    "    return Batch(src, trg, pad_idx)\n",
    "\n",
    "# Skip if not interested in multigpu.\n",
    "class MultiGPULossCompute:\n",
    "    \"A multi-gpu loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, devices, opt=None, chunk_size=5):\n",
    "        # Send out to different gpus.\n",
    "        self.generator = generator\n",
    "        self.criterion = nn.parallel.replicate(criterion, \n",
    "                                               devices=devices)\n",
    "        self.opt = opt\n",
    "        self.devices = devices\n",
    "        self.chunk_size = chunk_size\n",
    "        \n",
    "    def __call__(self, out, targets, normalize):\n",
    "        total = 0.0\n",
    "        generator = nn.parallel.replicate(self.generator, \n",
    "                                                devices=self.devices)\n",
    "        out_scatter = nn.parallel.scatter(out, \n",
    "                                          target_gpus=self.devices)\n",
    "        out_grad = [[] for _ in out_scatter]\n",
    "        targets = nn.parallel.scatter(targets, \n",
    "                                      target_gpus=self.devices)\n",
    "\n",
    "        # Divide generating into chunks.\n",
    "        chunk_size = self.chunk_size\n",
    "        for i in range(0, out_scatter[0].size(1), chunk_size):\n",
    "            # Predict distributions\n",
    "            out_column = [[Variable(o[:, i:i+chunk_size].data, \n",
    "                                    requires_grad=self.opt is not None)] \n",
    "                           for o in out_scatter]\n",
    "            gen = nn.parallel.parallel_apply(generator, out_column)\n",
    "\n",
    "            # Compute loss. \n",
    "            y = [(g.contiguous().view(-1, g.size(-1)), \n",
    "                  t[:, i:i+chunk_size].contiguous().view(-1)) \n",
    "                 for g, t in zip(gen, targets)]\n",
    "            loss = nn.parallel.parallel_apply(self.criterion, y)\n",
    "\n",
    "            # Sum and normalize loss\n",
    "            l = nn.parallel.gather(loss, \n",
    "                                   target_device=self.devices[0])\n",
    "            # l = l.sum()[0] / normalize\n",
    "            # total += l.data[0]\n",
    "            l = l.sum() / normalize\n",
    "            total += l.data\n",
    "\n",
    "            # Backprop loss to output of transformer\n",
    "            if self.opt is not None:\n",
    "                l.backward()\n",
    "                for j, l in enumerate(loss):\n",
    "                    out_grad[j].append(out_column[j][0].grad.data.clone())\n",
    "\n",
    "        # Backprop all loss through transformer.            \n",
    "        if self.opt is not None:\n",
    "            out_grad = [Variable(torch.cat(og, dim=1)) for og in out_grad]\n",
    "            o1 = out\n",
    "            o2 = nn.parallel.gather(out_grad, \n",
    "                                    target_device=self.devices[0])\n",
    "            o1.backward(gradient=o2)\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return total * normalize\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model, criterion, optimizer, data iterators, and paralelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py3/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/opt/conda/envs/py3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "# GPUs to use\n",
    "devices = [0]\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if True:\n",
    "    pad_idx = TGT.vocab.stoi[\"<blank>\"]\n",
    "    model = make_model(len(SRC.vocab), len(TGT.vocab), N=6)\n",
    "    model = model.cuda()\n",
    "    # model.to(device)\n",
    "    criterion = LabelSmoothing(size=len(TGT.vocab), padding_idx=pad_idx, smoothing=0.1)\n",
    "    criterion = criterion.cuda()\n",
    "    BATCH_SIZE = 1200\n",
    "    train_iter = MyIterator(train, batch_size=BATCH_SIZE, device=0,\n",
    "                            repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                            batch_size_fn=batch_size_fn, train=True)\n",
    "    valid_iter = MyIterator(val, batch_size=BATCH_SIZE, device=0,\n",
    "                            repeat=False, sort_key=lambda x: (len(x.src), len(x.trg)),\n",
    "                            batch_size_fn=batch_size_fn, train=False)\n",
    "    model_par = nn.DataParallel(model, device_ids=devices)\n",
    "    \n",
    "# None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py3/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 6.950817 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 6.260202 Tokens per Sec: 2727.000000\n",
      "Epoch Step: 101 Loss: 5.893045 Tokens per Sec: 2753.000000\n",
      "Epoch Step: 151 Loss: 5.235446 Tokens per Sec: 2756.000000\n",
      "Epoch Step: 201 Loss: 4.578382 Tokens per Sec: 2745.000000\n",
      "Epoch Step: 1 Loss: 3.758191 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 3.730635 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 3.687315 Tokens per Sec: 13600.000000\n",
      "tensor(3.9154, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 3.803216 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 3.362854 Tokens per Sec: 2739.000000\n",
      "Epoch Step: 101 Loss: 3.382906 Tokens per Sec: 2756.000000\n",
      "Epoch Step: 151 Loss: 3.035869 Tokens per Sec: 2744.000000\n",
      "Epoch Step: 201 Loss: 2.673637 Tokens per Sec: 2724.000000\n",
      "Epoch Step: 1 Loss: 2.531282 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 2.560647 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 2.440714 Tokens per Sec: 13600.000000\n",
      "tensor(2.7387, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.376941 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 2.735588 Tokens per Sec: 2712.000000\n",
      "Epoch Step: 101 Loss: 2.475255 Tokens per Sec: 2814.000000\n",
      "Epoch Step: 151 Loss: 2.235353 Tokens per Sec: 2743.000000\n",
      "Epoch Step: 201 Loss: 2.435258 Tokens per Sec: 2700.000000\n",
      "Epoch Step: 1 Loss: 2.051027 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 2.115897 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 1.900226 Tokens per Sec: 13600.000000\n",
      "tensor(2.2389, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 2.818861 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 2.622845 Tokens per Sec: 2690.000000\n",
      "Epoch Step: 101 Loss: 1.976679 Tokens per Sec: 2703.000000\n",
      "Epoch Step: 151 Loss: 1.824024 Tokens per Sec: 2784.000000\n",
      "Epoch Step: 201 Loss: 2.255634 Tokens per Sec: 2776.000000\n",
      "Epoch Step: 1 Loss: 1.861305 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.938118 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 1.607628 Tokens per Sec: 13600.000000\n",
      "tensor(1.9793, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.965436 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.922874 Tokens per Sec: 2753.000000\n",
      "Epoch Step: 101 Loss: 1.529966 Tokens per Sec: 2740.000000\n",
      "Epoch Step: 151 Loss: 1.876197 Tokens per Sec: 2716.000000\n",
      "Epoch Step: 201 Loss: 1.815474 Tokens per Sec: 2783.000000\n",
      "Epoch Step: 1 Loss: 1.761279 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.820057 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 1.444013 Tokens per Sec: 13600.000000\n",
      "tensor(1.8164, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.613847 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.508984 Tokens per Sec: 2797.000000\n",
      "Epoch Step: 101 Loss: 1.654364 Tokens per Sec: 2729.000000\n",
      "Epoch Step: 151 Loss: 1.603386 Tokens per Sec: 2794.000000\n",
      "Epoch Step: 201 Loss: 1.578668 Tokens per Sec: 2773.000000\n",
      "Epoch Step: 1 Loss: 1.659659 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.731206 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 1.368051 Tokens per Sec: 13600.000000\n",
      "tensor(1.7008, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.557087 Tokens per Sec: 2280.000000\n",
      "Epoch Step: 51 Loss: 1.393195 Tokens per Sec: 2799.000000\n",
      "Epoch Step: 101 Loss: 1.363581 Tokens per Sec: 2693.000000\n",
      "Epoch Step: 151 Loss: 1.363022 Tokens per Sec: 2736.000000\n",
      "Epoch Step: 201 Loss: 1.266581 Tokens per Sec: 2765.000000\n",
      "Epoch Step: 1 Loss: 1.653948 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.660125 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 1.325868 Tokens per Sec: 13600.000000\n",
      "tensor(1.6237, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.143912 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.273789 Tokens per Sec: 2731.000000\n",
      "Epoch Step: 101 Loss: 0.925639 Tokens per Sec: 2686.000000\n",
      "Epoch Step: 151 Loss: 1.301847 Tokens per Sec: 2749.000000\n",
      "Epoch Step: 201 Loss: 1.411300 Tokens per Sec: 2772.000000\n",
      "Epoch Step: 1 Loss: 1.624206 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.689816 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 1.142609 Tokens per Sec: 13600.000000\n",
      "tensor(1.5886, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 1.010909 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.195935 Tokens per Sec: 2784.000000\n",
      "Epoch Step: 101 Loss: 1.690764 Tokens per Sec: 2750.000000\n",
      "Epoch Step: 151 Loss: 1.482881 Tokens per Sec: 2725.000000\n",
      "Epoch Step: 201 Loss: 1.510440 Tokens per Sec: 2720.000000\n",
      "Epoch Step: 1 Loss: 1.567998 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.621209 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 1.186848 Tokens per Sec: 13600.000000\n",
      "tensor(1.5494, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.960641 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.083983 Tokens per Sec: 2754.000000\n",
      "Epoch Step: 101 Loss: 1.286194 Tokens per Sec: 2771.000000\n",
      "Epoch Step: 151 Loss: 1.331033 Tokens per Sec: 2751.000000\n",
      "Epoch Step: 201 Loss: 1.009125 Tokens per Sec: 2743.000000\n",
      "Epoch Step: 1 Loss: 1.562221 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.582720 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 1.058825 Tokens per Sec: 13600.000000\n",
      "tensor(1.4794, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.827677 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 0.941094 Tokens per Sec: 2732.000000\n",
      "Epoch Step: 101 Loss: 0.985078 Tokens per Sec: 2753.000000\n",
      "Epoch Step: 151 Loss: 0.850888 Tokens per Sec: 2688.000000\n",
      "Epoch Step: 201 Loss: 1.139718 Tokens per Sec: 2888.000000\n",
      "Epoch Step: 1 Loss: 1.559355 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.542615 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 1.088804 Tokens per Sec: 13600.000000\n",
      "tensor(1.4360, device='cuda:0')\n",
      "Epoch Step: 1 Loss: 0.656772 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 0.639643 Tokens per Sec: 3103.000000\n",
      "Epoch Step: 101 Loss: 0.562925 Tokens per Sec: 2987.000000\n",
      "Epoch Step: 151 Loss: 0.896305 Tokens per Sec: 2702.000000\n",
      "Epoch Step: 201 Loss: 0.944670 Tokens per Sec: 2730.000000\n",
      "Epoch Step: 1 Loss: 1.556495 Tokens per Sec: 4294967295.000000\n",
      "Epoch Step: 51 Loss: 1.549318 Tokens per Sec: 13187.000000\n",
      "Epoch Step: 101 Loss: 0.936286 Tokens per Sec: 13600.000000\n",
      "tensor(1.3986, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    model_opt = NoamOpt(model.src_embed[0].d_model, 1, 2000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "    for epoch in range(12):\n",
    "        model_par.train()\n",
    "        \n",
    "        run_epoch((rebatch(pad_idx, b) for b in train_iter), \n",
    "                  model_par, \n",
    "                  MultiGPULossCompute(model.generator, criterion, \n",
    "                                      devices=devices, opt=model_opt))\n",
    "        model_par.eval()\n",
    "        loss = run_epoch((rebatch(pad_idx, b) for b in valid_iter), \n",
    "                          model_par, \n",
    "                          MultiGPULossCompute(model.generator, criterion, \n",
    "                          devices=devices, opt=None))\n",
    "        print(loss)        \n",
    "else:\n",
    "    print('import model')\n",
    "    model = torch.load(\"iwslt.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = 'model/lc_epoch_12.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = 'model/lc_epoch_12.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py3/lib/python3.6/site-packages/ipykernel/__main__.py:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(1611, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(2741, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=512, out_features=2741, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_model(len(SRC.vocab), len(TGT.vocab), N=6)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 265,    6, 1542,  236,   86,   55,    0,    0,    0,  294, 1005,   55,\n",
      "           20,   66,  821,  618,  607,   58,   98,   19,    0,  905, 1276,    0,\n",
      "         1002,  343,  820, 1352,  136,  122]])\n",
      "**************************************************************************************************************\n",
      "Source:\t风衣女中长款2018春秋装新款连帽chic收腰系带韩国学生宽松bf外套\n",
      "Generated:\tmon##cle##r（盟可睐）这款连帽外套以一袭红色抓人眼球，两侧的荷叶边带来可爱感觉，轻松为你的造型注入年轻活力。\n",
      "tensor([[ 367,  339, 1542,  999,    0,    0,  241,    6, 1542,    0,  339,    0,\n",
      "           17,  122,  294,  236,  617,  908,   47,   41,  156,   56,    0,    0,\n",
      "          122,  294,    0,    0]])\n",
      "**************************************************************************************************************\n",
      "Source:\t超厚女士保暖内衣女加厚加绒套装中青年圆领修身保暖套装冬季\n",
      "Generated:\tst##ella##mc##car##t##ney（丝黛拉麦卡妮）这款初剪羊毛紧身裤采用料精心制作，结合防泼水、防风等多项功能，让你能安心舒适、灵活性及时尚\n",
      "tensor([[   0, 1007,   82,  182,  294,  157,  182,    0,  182, 1542,  182,    0,\n",
      "           17,    0,  339,    0,    0,  612,    6,    0,    0,  180,  122,  294,\n",
      "          236,  138,  182,    0,    0,  294]])\n",
      "**************************************************************************************************************\n",
      "Source:\t南极人童装儿童男童女童加绒加厚保暖睡衣家居服套装中大童秋冬装\n",
      "Generated:\tis##la这款黑色西服外套充满童趣玩味，以粉色皮毛绒面小朋友的造型与柔软细腻质感。\n",
      "tensor([[   0,    0,    0, 1005,   55,    0,   98,  608,   66,   47,   41,  237,\n",
      "            6,    0,  999,  222,  225, 1002,  343,    3,   25,  122,  105,   21,\n",
      "            0,   95,    0,    0,  136,  122]])\n",
      "**************************************************************************************************************\n",
      "Source:\t春秋季新款日系无帽圆领卫衣男士休闲宽松拼色套头衫潮牌嘻哈外套\n",
      "Generated:\topen##ing##cer##em##on##y这款休闲套装的设计充满新鲜活力，松紧带及背面的品牌名称带来辨识度，轻松为你的造型注入摩登活力。\n"
     ]
    }
   ],
   "source": [
    "## predict online\n",
    "name_lis = ['风衣女中长款2018春秋装新款连帽chic收腰系带韩国学生宽松bf外套', \n",
    "           '超厚女士保暖内衣女加厚加绒套装中青年圆领修身保暖套装冬季',\n",
    "           '南极人童装儿童男童女童加绒加厚保暖睡衣家居服套装中大童秋冬装',\n",
    "           '春秋季新款日系无帽圆领卫衣男士休闲宽松拼色套头衫潮牌嘻哈外套']\n",
    "def predict_online(s):\n",
    "    product_name = s\n",
    "    example = data.Example.fromlist([product_name, ''], \n",
    "                                fields=[('src', SRC), ('trg', TGT)])\n",
    "    src = torch.LongTensor([list(SRC.vocab.stoi[s] for s in example.src)])\n",
    "    print(src)\n",
    "    src = src.cuda()\n",
    "    src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "    src_mask = src_mask.cuda()\n",
    "    out = greedy_decode(model, src, src_mask, \n",
    "                        max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
    "    print('*'*110)\n",
    "    print(\"Source:\", end=\"\\t\")\n",
    "    print(product_name)\n",
    "    print(\"Generated:\", end=\"\\t\")\n",
    "    for i in range(1, out.size(1)):\n",
    "        sym = TGT.vocab.itos[out[0, i]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "for _ in name_lis:\n",
    "    predict_online(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epoch=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************************************************************\n",
      "Source:\t暗 花 纹 长 裤 \n",
      "Generated:\tvictoria , victoria ##be ##ck ##ham 以 羽 毛 般 的 笔 触 印 花 点 缀 这 款 长 裤 ， 黑 白 色 组 合 经 典 摩 登 ， 为 你 的 造 型 渲 染 现 代 艺 术 色 彩 。 \n",
      "Target:\tvictoria , victoria ##be ##ck ##ham 这 款 长 裤 触 感 柔 滑 ， 细 腻 的 暗 花 纹 与 浅 粉 色 背 景 相 得 益 彰 。 不 妨 与 同 系 列 西 服 夹 克 成 套 穿 着 ， 打 造 柔 美 与 率 性 兼 备 的 都 市 造 型 。 \n",
      "************************************************************************************************************************\n",
      "Source:\t微 喇 叭 露 踝 裤 \n",
      "Generated:\tvictoria , victoria ##be ##ck ##ham 这 款 黑 色 露 踝 裤 以 微 喇 叭 剪 裁 带 来 优 雅 风 情 ， 为 你 的 简 约 都 市 造 型 注 入 一 丝 女 人 味 。 \n",
      "Target:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 露 踝 裤 低 调 大 方 ， 微 喇 叭 裤 腿 带 来 些 许 复 古 感 觉 。 不 妨 搭 配 深 色 西 服 外 套 ， 打 造 率 性 都 市 造 型 。 \n",
      "************************************************************************************************************************\n",
      "Source:\t拼 接 设 计 围 巾 \n",
      "Generated:\tjan ##av ##i 这 款 围 巾 选 用 柔 软 的 精 细 美 丽 诺 羊 毛 面 料 制 造 ， 左 右 纹 理 及 色 彩 对 比 营 造 出 层 次 变 化 ， 充 分 呼 应 了 简 约 摩 登 美 学 。 \n",
      "Target:\tat ##el ##ier & amp ; re ##pa ##ir ##s 秉 承 环 保 理 念 ， 仅 采 用 工 <unk> 生 产 过 程 中 的 废 余 布 料 打 造 时 尚 服 饰 ， 以 前 卫 设 计 赋 予 面 料 二 次 新 生 。 这 款 围 巾 将 不 同 色 彩 与 印 花 重 新 拼 接 组 合 ， 呈 现 出 充 满 张 力 的 视 觉 效 果 。 \n",
      "************************************************************************************************************************\n",
      "Source:\tpa ##z 真 皮 乐 福 鞋 \n",
      "Generated:\t这 款 真 皮 乐 福 鞋 舒 适 耐 穿 ， 从 廓 形 到 配 色 都 展 现 出 vi ##nce 的 简 约 基 因 ， 无 论 搭 配 都 市 或 休 闲 造 型 都 十 分 适 宜 。 \n",
      "Target:\t这 款 真 皮 乐 福 鞋 舒 适 耐 穿 ， 从 廓 形 到 配 色 都 展 现 出 vi ##nce 的 简 约 基 因 ， 无 论 搭 配 都 市 或 休 闲 造 型 都 十 分 适 宜 。 \n",
      "************************************************************************************************************************\n",
      "Source:\t纯 色 连 帽 卫 衣 裙 \n",
      "Generated:\tt ##ho ##mb ##row ##ne 的 四 重 条 纹 已 成 为 品 牌 颇 具 辨 识 度 的 元 素 之 一 ， 不 妨 这 以 这 款 深 蓝 色 连 衣 裙 搭 配 同 系 列 休 闲 裤 ， 打 造 舒 适 又 摩 登 的 日 常 造 型 \n",
      "Target:\ttb ##ya ##lex ##and ##er ##wang 将 卫 衣 廓 形 融 入 这 款 红 色 连 衣 裙 ， 富 有 运 动 气 息 的 同 时 不 失 女 性 特 质 ， 搭 配 黑 色 尖 头 短 靴 便 是 摩 登 街 头 造 型 。 \n",
      "************************************************************************************************************************\n",
      "Source:\t骷 髅 头 吊 坠 耳 环 \n",
      "Generated:\t骷 髅 头 乃 alexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 的 经 典 设 计 元 素 ， 这 款 耳 环 以 精 致 闪 亮 的 仿 水 晶 平 衡 骷 髅 头 吊 坠 的 暗 黑 气 息 ， 是 搭 配 摩 登 造 型 的 理 \n",
      "Target:\talexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 这 款 耳 环 以 别 具 辨 识 度 的 骷 髅 头 吊 坠 营 造 酷 感 气 息 ， 配 以 一 颗 颗 闪 烁 的 施 华 洛 世 奇 仿 水 晶 ， 在 你 的 耳 畔 绽 放 光 芒 。 \n",
      "************************************************************************************************************************\n",
      "Source:\t包 裹 式 纯 棉 半 裙 \n",
      "Generated:\tvi ##nce 这 款 包 裹 式 半 裙 简 约 百 搭 ， 人 造 皮 革 腰 带 增 添 了 几 分 摩 登 个 性 ， 轻 松 点 亮 你 的 都 市 造 型 。 \n",
      "Target:\tj . cr ##ick ##et 这 款 卡 其 绿 色 半 裙 兼 具 硬 朗 与 优 雅 感 觉 ， 采 用 纯 棉 面 料 裁 剪 出 流 畅 线 条 ， 包 布 钮 扣 腰 带 悄 然 提 升 了 单 品 的 设 计 感 ， 搭 配 蕾 丝 衬 衫 与 运 动 鞋 便 是 亦 刚 亦 柔 的 都 市 造 型 。 \n",
      "************************************************************************************************************************\n",
      "Source:\t印 花 拼 接 真 丝 围 巾 \n",
      "Generated:\tf ##ran ##co ##fer ##ra ##ri 这 款 真 丝 围 巾 以 两 幅 感 觉 截 然 不 同 的 印 花 带 来 视 觉 冲 击 。 一 边 缀 有 艳 丽 绽 放 的 花 卉 ， 另 一 边 是 由 绳 结 所 组 成 的 抽 象 图 案 ， \n",
      "Target:\tf ##ran ##co ##fer ##ra ##ri 这 款 真 丝 围 巾 以 两 幅 感 觉 截 然 不 同 的 图 案 带 来 视 觉 冲 击 ， 彰 显 你 的 摩 登 个 性 。 \n",
      "************************************************************************************************************************\n",
      "Source:\t混 羊 绒 针 织 阔 腿 裤 \n",
      "Generated:\tvi ##nce 这 款 针 织 阔 腿 裤 采 用 羊 绒 面 料 制 造 ， 质 感 柔 软 细 腻 。 浅 灰 色 设 计 素 雅 大 方 ， 无 论 搭 配 休 闲 或 都 市 造 型 都 十 分 相 宜 。 \n",
      "Target:\tcr ##ush ##co ##lle ##ction 这 款 针 织 阔 腿 裤 质 感 柔 软 舒 适 ， 设 计 简 约 百 搭 。 不 妨 搭 配 同 色 针 织 衫 ， 打 造 浑 然 一 体 的 休 闲 造 型 。 \n",
      "************************************************************************************************************************\n",
      "Source:\t编 织 曲 线 羊 毛 大 衣 \n",
      "Generated:\tac ##nes ##tu ##dio ##s 这 款 大 衣 以 混 马 海 毛 及 羊 毛 面 料 带 来 毛 绒 般 的 质 感 ， 穿 着 温 暖 舒 适 ， 是 低 调 大 气 的 秋 冬 单 品 。 \n",
      "Target:\t编 织 元 素 已 经 成 为 x ##u ##z ##hi 的 标 志 性 元 素 。 这 款 羊 毛 大 衣 点 缀 了 一 条 条 <unk> 密 排 列 的 编 织 曲 线 ， 为 简 洁 单 品 注 入 流 动 美 感 。 \n"
     ]
    }
   ],
   "source": [
    "# greedy search\n",
    "for i, batch in enumerate(valid_iter):\n",
    "    if i >= 10:\n",
    "        break\n",
    "        \n",
    "    src = batch.src.transpose(0, 1)[:1]\n",
    "    src = src.cuda()\n",
    "    src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "    src_mask = src_mask.cuda()\n",
    "    out = greedy_decode(model, src, src_mask, \n",
    "                        max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
    "    print('*'*110)\n",
    "    print(\"Source:\", end=\"\\t\")\n",
    "    for i in range(0, batch.src.size(0)):\n",
    "        sym = SRC.vocab.itos[batch.src.data[i, 0]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "    print(\"Generated:\", end=\"\\t\")\n",
    "    for i in range(1, out.size(1)):\n",
    "        sym = TGT.vocab.itos[out[0, i]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "    print(\"Target:\", end=\"\\t\")\n",
    "    for i in range(1, batch.trg.size(0)):\n",
    "        sym = TGT.vocab.itos[batch.trg.data[i, 0]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epoch=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************************************************************************\n",
      "Source:\t暗 花 纹 长 裤 \n",
      "Generated:\tvictoria , victoria ##be ##ck ##ham 这 款 长 裤 剪 裁 流 畅 利 落 ， 淡 粉 色 设 计 衬 托 出 你 的 笔 直 双 腿 ， 是 打 造 摩 登 都 市 造 型 的 百 搭 之 选 。 \n",
      "Target:\tvictoria , victoria ##be ##ck ##ham 这 款 长 裤 触 感 柔 滑 ， 细 腻 的 暗 花 纹 与 浅 粉 色 背 景 相 得 益 彰 。 不 妨 与 同 系 列 西 服 夹 克 成 套 穿 着 ， 打 造 柔 美 与 率 性 兼 备 的 都 市 造 型 。 \n",
      "**************************************************************************************************************\n",
      "Source:\t微 喇 叭 露 踝 裤 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 露 踝 裤 以 微 喇 叭 裤 腿 营 造 复 古 氛 围 ， 不 妨 搭 配 同 品 牌 印 花 t 恤 ， 打 造 摩 登 都 市 造 型 。 \n",
      "Target:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 露 踝 裤 低 调 大 方 ， 微 喇 叭 裤 腿 带 来 些 许 复 古 感 觉 。 不 妨 搭 配 深 色 西 服 外 套 ， 打 造 率 性 都 市 造 型 。 \n",
      "**************************************************************************************************************\n",
      "Source:\t拼 接 设 计 围 巾 \n",
      "Generated:\tf ##ran ##co ##fer ##ra ##ri 这 款 围 巾 采 用 羊 毛 混 丝 面 料 制 作 ， 拼 色 设 计 带 来 层 次 变 化 ， 轻 松 点 亮 你 的 日 常 造 型 。 \n",
      "Target:\tat ##el ##ier & amp ; re ##pa ##ir ##s 秉 承 环 保 理 念 ， 仅 采 用 工 <unk> 生 产 过 程 中 的 废 余 布 料 打 造 时 尚 服 饰 ， 以 前 卫 设 计 赋 予 面 料 二 次 新 生 。 这 款 围 巾 将 不 同 色 彩 与 印 花 重 新 拼 接 组 合 ， 呈 现 出 充 满 张 力 的 视 觉 效 果 。 \n",
      "**************************************************************************************************************\n",
      "Source:\tpa ##z 真 皮 乐 福 鞋 \n",
      "Generated:\tsam ##ed ##el ##man 这 款 白 色 真 皮 乐 福 鞋 舒 适 耐 穿 ， 从 廓 形 到 底 设 计 都 弥 漫 着 酷 感 十 足 ， 是 日 常 百 搭 的 休 闲 单 品 。 \n",
      "Target:\t这 款 真 皮 乐 福 鞋 舒 适 耐 穿 ， 从 廓 形 到 配 色 都 展 现 出 vi ##nce 的 简 约 基 因 ， 无 论 搭 配 都 市 或 休 闲 造 型 都 十 分 适 宜 。 \n",
      "**************************************************************************************************************\n",
      "Source:\t纯 色 连 帽 卫 衣 裙 \n",
      "Generated:\tt ##ho ##mb ##row ##ne 这 款 深 蓝 色 连 帽 卫 衣 采 用 轻 盈 舒 适 的 日 本 棉 鱼 鳞 布 制 作 ， 不 妨 搭 配 黑 色 休 闲 裤 ， 打 造 简 约 休 闲 造 型 。 \n",
      "Target:\ttb ##ya ##lex ##and ##er ##wang 将 卫 衣 廓 形 融 入 这 款 红 色 连 衣 裙 ， 富 有 运 动 气 息 的 同 时 不 失 女 性 特 质 ， 搭 配 黑 色 尖 头 短 靴 便 是 摩 登 街 头 造 型 。 \n",
      "**************************************************************************************************************\n",
      "Source:\t骷 髅 头 吊 坠 耳 环 \n",
      "Generated:\talexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 这 款 耳 环 以 具 辨 识 度 的 骷 髅 头 吊 坠 带 来 酷 感 气 息 ， 配 以 一 颗 颗 闪 烁 的 施 华 洛 世 奇 仿 水 晶 ， 轻 松 点 亮 你 的 摩 登 \n",
      "Target:\talexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 这 款 耳 环 以 别 具 辨 识 度 的 骷 髅 头 吊 坠 营 造 酷 感 气 息 ， 配 以 一 颗 颗 闪 烁 的 施 华 洛 世 奇 仿 水 晶 ， 在 你 的 耳 畔 绽 放 光 芒 。 \n",
      "**************************************************************************************************************\n",
      "Source:\t包 裹 式 纯 棉 半 裙 \n",
      "Generated:\tdi ##on ##lee 这 款 半 裙 采 用 细 腻 的 桑 蚕 丝 缎 面 面 面 料 制 作 ， 包 裹 式 设 计 带 来 玩 味 一 笔 ， 搭 配 白 色 针 织 衫 及 短 靴 便 是 摩 登 都 市 造 型 。 \n",
      "Target:\tj . cr ##ick ##et 这 款 卡 其 绿 色 半 裙 兼 具 硬 朗 与 优 雅 感 觉 ， 采 用 纯 棉 面 料 裁 剪 出 流 畅 线 条 ， 包 布 钮 扣 腰 带 悄 然 提 升 了 单 品 的 设 计 感 ， 搭 配 蕾 丝 衬 衫 与 运 动 鞋 便 是 亦 刚 亦 柔 的 都 市 造 型 。 \n",
      "**************************************************************************************************************\n",
      "Source:\t印 花 拼 接 真 丝 围 巾 \n",
      "Generated:\tf ##ran ##co ##fer ##ra ##ri 这 款 真 丝 围 巾 以 不 同 深 蓝 色 印 花 带 来 视 觉 玩 味 ， 轻 松 点 亮 你 的 摩 登 休 闲 造 型 。 \n",
      "Target:\tf ##ran ##co ##fer ##ra ##ri 这 款 真 丝 围 巾 以 两 幅 感 觉 截 然 不 同 的 图 案 带 来 视 觉 冲 击 ， 彰 显 你 的 摩 登 个 性 。 \n",
      "**************************************************************************************************************\n",
      "Source:\t混 羊 绒 针 织 阔 腿 裤 \n",
      "Generated:\tvictoria ##be ##ck ##ham （ 维 多 利 亚 贝 克 汉 姆 ） 这 款 阔 腿 裤 采 用 柔 软 舒 适 的 羊 绒 面 料 制 作 ， 质 感 柔 软 舒 适 ， 是 打 造 休 闲 造 型 的 理 想 单 品 。 \n",
      "Target:\tcr ##ush ##co ##lle ##ction 这 款 针 织 阔 腿 裤 质 感 柔 软 舒 适 ， 设 计 简 约 百 搭 。 不 妨 搭 配 同 色 针 织 衫 ， 打 造 浑 然 一 体 的 休 闲 造 型 。 \n",
      "**************************************************************************************************************\n",
      "Source:\t编 织 曲 线 羊 毛 大 衣 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 羊 毛 大 衣 以 一 袭 红 色 抓 人 眼 球 ， over ##si ##ze 廓 形 充 满 慵 懒 随 性 感 觉 ， 是 兼 具 现 代 摩 登 气 息 的 时 尚 单 品 。 \n",
      "Target:\t编 织 元 素 已 经 成 为 x ##u ##z ##hi 的 标 志 性 元 素 。 这 款 羊 毛 大 衣 点 缀 了 一 条 条 <unk> 密 排 列 的 编 织 曲 线 ， 为 简 洁 单 品 注 入 流 动 美 感 。 \n"
     ]
    }
   ],
   "source": [
    "# greedy search\n",
    "for i, batch in enumerate(valid_iter):\n",
    "    if i >= 10:\n",
    "        break\n",
    "        \n",
    "    src = batch.src.transpose(0, 1)[:1]\n",
    "    src = src.cuda()\n",
    "    src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "    src_mask = src_mask.cuda()\n",
    "    out = greedy_decode(model, src, src_mask, \n",
    "                        max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
    "    print('*'*110)\n",
    "    print(\"Source:\", end=\"\\t\")\n",
    "    for i in range(0, batch.src.size(0)):\n",
    "        sym = SRC.vocab.itos[batch.src.data[i, 0]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "    print(\"Generated:\", end=\"\\t\")\n",
    "    for i in range(1, out.size(1)):\n",
    "        sym = TGT.vocab.itos[out[0, i]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "    print(\"Target:\", end=\"\\t\")\n",
    "    for i in range(1, batch.trg.size(0)):\n",
    "        sym = TGT.vocab.itos[batch.trg.data[i, 0]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source:\t花 纹 长 裤 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 长 裤 通 身 缀 有 细 腻 褶 [UNK] ， 为 单 品 增 添 几 分 随 性 动 感 觉 ， 助 你 打 造 摩 登 都 市 造 型 。 \n",
      "Target:\tvictoria , victoria ##be ##ck ##ham 这 款 长 裤 触 感 柔 滑 ， 细 腻 的 暗 花 纹 与 浅 粉 色 背 景 相 得 益 彰 。 不 妨 与 同 系 列 西 服 夹 克 成 套 穿 着 ， 打 造 柔 美 与 率 性 兼 备 的 都 市 造 型 。 \n",
      "Source:\t喇 叭 露 踝 裤 \n",
      "Generated:\tne ##il ##bar ##re ##tt （ 尼 奥 贝 奈 特 ） 这 款 露 踝 裤 采 用 [UNK] 绸 面 料 制 作 ， 喇 叭 裤 腿 带 来 几 分 复 古 质 感 ， 助 你 打 造 摩 登 休 闲 造 型 。 \n",
      "Target:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 露 踝 裤 低 调 大 方 ， 微 喇 叭 裤 腿 带 来 些 许 复 古 感 觉 。 不 妨 搭 配 深 色 西 服 外 套 ， 打 造 率 性 都 市 造 型 。 \n",
      "Source:\t接 设 计 围 巾 \n",
      "Generated:\talexander ##wang （ 亚 历 山 大 王 ） 这 款 羊 毛 围 巾 利 用 拼 接 设 计 塑 造 出 鲜 明 的 色 彩 层 次 ， 为 你 的 造 型 增 添 几 分 女 人 味 。 \n",
      "Target:\tat ##el ##ier & amp ; re ##pa ##ir ##s 秉 承 环 保 理 念 ， 仅 采 用 工 <unk> 生 产 过 程 中 的 废 余 布 料 打 造 时 尚 服 饰 ， 以 前 卫 设 计 赋 予 面 料 二 次 新 生 。 这 款 围 巾 将 不 同 色 彩 与 印 花 重 新 拼 接 组 合 ， 呈 现 出 充 满 张 力 的 视 觉 效 果 。 \n",
      "Source:\t##z 真 皮 乐 福 鞋 \n",
      "Generated:\tsam ##ed ##el ##man 这 款 乐 福 鞋 舒 适 耐 穿 ， 白 色 真 皮 交 叉 搭 带 营 造 出 细 腻 层 次 感 ， 轻 松 升 级 你 的 休 闲 造 型 。 \n",
      "Target:\t这 款 真 皮 乐 福 鞋 舒 适 耐 穿 ， 从 廓 形 到 配 色 都 展 现 出 vi ##nce 的 简 约 基 因 ， 无 论 搭 配 都 市 或 休 闲 造 型 都 十 分 适 宜 。 \n",
      "Source:\t色 连 帽 卫 衣 裙 \n",
      "Generated:\tthe ##row 这 款 深 蓝 色 连 衣 裙 采 用 简 约 设 计 ， 剪 裁 勾 勒 出 你 的 身 形 线 条 ， 是 打 造 摩 登 休 闲 造 型 的 理 想 之 选 。 \n",
      "Target:\ttb ##ya ##lex ##and ##er ##wang 将 卫 衣 廓 形 融 入 这 款 红 色 连 衣 裙 ， 富 有 运 动 气 息 的 同 时 不 失 女 性 特 质 ， 搭 配 黑 色 尖 头 短 靴 便 是 摩 登 街 头 造 型 。 \n",
      "Source:\t髅 头 吊 坠 耳 环 \n",
      "Generated:\talexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 这 款 耳 环 采 用 光 滑 细 腻 的 小 牛 皮 制 作 ， 深 浅 色 骷 髅 头 指 环 扣 则 带 来 几 分 酷 感 气 息 ， 轻 松 升 级 你 的 摩 登 造 型 。 \n",
      "Target:\talexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 这 款 耳 环 以 别 具 辨 识 度 的 骷 髅 头 吊 坠 营 造 酷 感 气 息 ， 配 以 一 颗 颗 闪 烁 的 施 华 洛 世 奇 仿 水 晶 ， 在 你 的 耳 畔 绽 放 光 芒 。 \n",
      "Source:\t裹 式 纯 棉 半 裙 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 半 裙 采 用 斜 挎 包 裹 式 设 计 ， 两 件 式 搭 配 白 色 皮 裤 便 是 摩 登 都 市 造 型 。 \n",
      "Target:\tj . cr ##ick ##et 这 款 卡 其 绿 色 半 裙 兼 具 硬 朗 与 优 雅 感 觉 ， 采 用 纯 棉 面 料 裁 剪 出 流 畅 线 条 ， 包 布 钮 扣 腰 带 悄 然 提 升 了 单 品 的 设 计 感 ， 搭 配 蕾 丝 衬 衫 与 运 动 鞋 便 是 亦 刚 亦 柔 的 都 市 造 型 。 \n",
      "Source:\t花 拼 接 真 丝 围 巾 \n",
      "Generated:\tf ##ran ##co ##fer ##ra ##ri 这 款 围 巾 采 用 丝 线 制 造 ， 拼 色 设 计 带 来 几 分 复 古 感 觉 ， 轻 松 升 级 你 的 摩 登 造 型 。 \n",
      "Target:\tf ##ran ##co ##fer ##ra ##ri 这 款 真 丝 围 巾 以 两 幅 感 觉 截 然 不 同 的 图 案 带 来 视 觉 冲 击 ， 彰 显 你 的 摩 登 个 性 。 \n",
      "Source:\t羊 绒 针 织 阔 腿 裤 \n",
      "Generated:\tthe ##row 这 款 深 蓝 色 阔 腿 裤 采 用 羊 绒 面 料 制 作 ， 质 感 柔 软 舒 适 。 设 计 简 约 低 调 百 搭 ， 是 打 造 休 闲 造 型 的 理 想 之 选 。 \n",
      "Target:\tcr ##ush ##co ##lle ##ction 这 款 针 织 阔 腿 裤 质 感 柔 软 舒 适 ， 设 计 简 约 百 搭 。 不 妨 搭 配 同 色 针 织 衫 ， 打 造 浑 然 一 体 的 休 闲 造 型 。 \n",
      "Source:\t织 曲 线 羊 毛 大 衣 \n",
      "Generated:\tji ##nn ##nn 这 款 大 衣 采 用 温 暖 舒 适 的 羊 毛 混 羊 绒 面 料 制 作 ， 穿 着 十 分 舒 适 。 不 妨 搭 配 同 色 系 上 衣 及 短 靴 ， 打 造 个 性 休 闲 造 型 。 \n",
      "Target:\t编 织 元 素 已 经 成 为 x ##u ##z ##hi 的 标 志 性 元 素 。 这 款 羊 毛 大 衣 点 缀 了 一 条 条 <unk> 密 排 列 的 编 织 曲 线 ， 为 简 洁 单 品 注 入 流 动 美 感 。 \n",
      "Source:\t割 衣 袖 西 服 夹 克 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 西 服 夹 克 利 用 钮 扣 带 来 几 分 硬 朗 感 觉 ， 不 妨 搭 配 同 色 系 的 切 割 短 靴 ， 打 造 摩 登 都 市 造 型 。 \n",
      "Target:\tne ##il ##bar ##re ##tt （ 尼 奥 贝 奈 特 ） 这 款 西 服 外 套 巧 妙 利 用 切 割 衣 袖 打 造 斗 篷 式 效 果 ， 为 简 约 都 市 单 品 注 入 新 鲜 感 之 余 亦 助 你 展 现 强 大 气 场 。 \n",
      "Source:\t对 称 罗 纹 针 织 衫 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 针 织 衫 利 用 对 比 鲜 明 的 色 设 计 营 造 视 觉 张 力 ， 轻 松 为 你 的 休 闲 造 型 添 上 摩 登 一 笔 。 \n",
      "Target:\tch ##lo ##e （ 蔻 依 ） 这 款 针 织 衫 集 厚 实 面 料 与 轻 盈 质 感 于 一 身 。 不 对 称 罗 纹 呈 现 出 细 腻 流 畅 感 觉 ， 搭 配 同 品 牌 百 褶 印 花 裙 便 是 仙 气 满 满 的 女 人 味 造 型 。 \n",
      "Source:\t布 拉 多 吊 坠 耳 环 \n",
      "Generated:\tken ##net ##h ##ja ##y ##lan ##e 这 款 耳 环 采 用 镀 [UNK] 金 属 打 造 出 丰 富 的 层 次 感 ， 是 打 造 摩 登 休 闲 造 型 的 理 想 配 饰 。 \n",
      "Target:\t为 庆 祝 2018 <unk> 历 狗 年 ， de ##ye ##en （ 得 音 ） 推 出 一 系 列 [UNK] 萌 意 浓 浓 [UNK] 的 宠 物 主 题 饰 物 ， 这 款 耳 环 以 小 巧 的 脚 印 耳 钉 呼 应 拉 布 拉 多 吊 坠 ， 于 细 节 处 彰 显 你 的 天 真 童 趣 一 面 。 \n",
      "Source:\t宝 石 开 口 圆 环 耳 环 \n",
      "Generated:\tken ##net ##h ##ja ##y ##lan ##e 这 款 耳 环 采 用 镀 银 金 属 打 造 出 ， 两 边 分 别 为 你 的 造 型 增 添 几 分 摩 登 气 息 。 \n",
      "Target:\tken ##net ##h ##ja ##y ##lan ##e 这 款 黑 色 开 口 耳 环 风 格 现 代 简 约 ， 轻 松 升 级 你 的 时 尚 造 型 。 \n",
      "Source:\t水 晶 双 重 吊 坠 耳 环 \n",
      "Generated:\tken ##net ##h ##ja ##y ##lan ##e 这 款 耳 环 采 用 镀 银 金 属 打 造 出 方 正 廓 形 ， 整 的 仿 水 晶 更 添 璀 璨 光 芒 ， 为 你 的 造 型 增 添 几 分 摩 登 气 息 。 \n",
      "Target:\tken ##net ##h ##ja ##y ##lan ##e 这 款 耳 环 的 吊 坠 缀 有 一 颗 颗 仿 水 晶 ， 随 你 步 履 在 耳 边 轻 摇 摆 动 ， 散 发 阵 阵 亮 眼 光 芒 。 \n",
      "Source:\t叠 布 饰 羊 毛 针 织 衫 \n",
      "Generated:\tmr ##z 这 款 针 织 衫 采 用 温 暖 舒 适 的 羊 毛 混 羊 绒 面 料 制 作 ， 可 拆 式 腰 带 让 你 随 时 转 换 不 同 造 型 ， 是 时 尚 实 穿 的 百 搭 单 品 。 \n",
      "Target:\tff ##ix ##x ##ed ##st ##ud ##io ##s 这 款 羊 毛 针 织 衫 温 暖 舒 适 ， 领 口 的 搭 叠 布 饰 塑 造 出 宛 若 佩 戴 着 围 巾 的 趣 味 效 果 ， 别 具 时 尚 玩 味 。 \n",
      "Source:\t肩 设 计 真 丝 衬 衫 裙 \n",
      "Generated:\teq ##ui ##l 这 款 衬 衫 的 设 计 充 满 现 代 感 ， 不 妨 搭 配 白 色 阔 腿 裤 ， 打 造 简 约 素 雅 的 休 闲 造 型 。 \n",
      "Target:\tms ##min 这 款 真 丝 衬 衫 裙 仙 气 满 满 ， 落 肩 设 计 与 宽 松 版 型 带 来 随 性 闲 适 气 息 。 不 妨 搭 配 黑 色 漆 皮 系 带 鞋 ， 打 造 简 约 典 雅 的 休 闲 造 型 。 \n",
      "Source:\t钻 石 18k 玫 瑰 金 耳 钉 \n",
      "Generated:\tof ##ee 的 设 计 充 满 简 约 优 雅 的 法 式 情 调 。 这 款 耳 钉 以 纤 细 的 金 色 勾 勒 出 单 品 的 轮 廓 ， 令 你 的 造 型 更 具 摩 登 魅 力 。 \n",
      "Target:\t来 自 法 国 的 珠 宝 品 牌 of ##ee 以 简 约 优 雅 的 设 计 刻 画 现 代 女 性 的 个 性 魅 力 。 这 款 18k 玫 瑰 金 耳 环 简 单 镶 嵌 一 颗 璀 璨 钻 石 ， 衬 托 你 落 落 大 方 的 气 质 。 \n",
      "Source:\t##el ##ee 羊 绒 针 织 外 套 \n",
      "Generated:\tthe ##row 这 款 深 蓝 色 针 织 外 套 采 用 羊 绒 面 料 制 作 ， 质 感 轻 柔 软 舒 适 。 设 计 师 巧 妙 地 以 深 浅 色 调 呈 现 出 鲜 明 的 色 调 ， 为 你 的 休 闲 造 型 增 添 一 抹 \n",
      "Target:\tt ##ho ##ery 这 款 针 织 外 套 贯 彻 品 牌 的 简 约 风 格 ， 采 用 轻 盈 的 羊 绒 面 料 精 心 制 造 ， 带 来 舒 适 亲 肤 的 穿 着 体 验 。 不 妨 搭 配 黑 色 阔 腿 裤 ， 打 造 简 约 大 方 的 都 市 造 型 。 \n",
      "Source:\t国 风 品 牌 标 志 t 恤 \n",
      "Generated:\tac ##nes ##tu ##dio ##s 这 款 t 恤 采 用 舒 适 柔 软 的 纯 棉 面 料 制 作 ， 左 胸 的 品 牌 名 称 为 单 品 增 添 玩 味 一 笔 ， 助 你 打 造 简 约 休 闲 造 型 。 \n",
      "Target:\talexander ##wang （ 亚 历 山 大 王 ） 今 季 进 行 [UNK] # wang ##ev ##ol ##ut ##ion [UNK] 大 变 身 ， 品 牌 标 志 亦 从 原 来 的 全 大 写 变 为 全 小 写 。 这 款 t 恤 将 美 国 国 <unk> 融 入 新 logo 之 中 ， 结 合 立 体 效 果 ， 别 具 个 性 玩 味 。 \n",
      "Source:\t丝 袖 口 牛 仔 连 体 裤 \n",
      "Generated:\tthe ##row 这 款 深 蓝 色 连 体 裤 采 用 初 剪 羊 毛 面 料 精 心 剪 裁 ， 利 落 肩 设 计 增 添 几 分 随 性 感 觉 ， 是 打 造 摩 登 造 型 的 理 想 单 品 。 \n",
      "Target:\t美 式 风 情 贯 穿 ph ##il ##os ##op ##hy ##di ##lor ##en ##zo ##ser ##af ##ini 整 个 2018 秋 冬 系 列 。 这 款 牛 仔 连 体 裤 以 工 作 服 版 型 营 造 摩 登 率 性 氛 围 ， 蕾 丝 袖 口 稍 微 平 衡 了 单 品 的 硬 朗 质 感 。 不 妨 搭 配 高 跟 鞋 ， 为 造 型 增 添 一 份 女 人 味 。 \n",
      "Source:\t玫 瑰 金 圆 形 金 属 耳 环 \n",
      "Generated:\tken ##net ##h ##ja ##y ##lan ##e 这 款 耳 环 采 用 镀 银 金 属 打 造 出 ， 纤 细 的 形 形 形 金 属 链 条 为 单 品 增 添 几 分 现 代 感 ， 轻 松 升 级 你 的 摩 登 都 市 造 型 。 \n",
      "Target:\tken ##net ##h ##ja ##y ##lan ##e 这 款 玫 瑰 金 色 圆 形 耳 环 简 约 低 调 ， 是 升 级 优 雅 造 型 的 理 想 款 式 。 \n",
      "Source:\t结 衣 领 真 丝 缎 面 上 衣 \n",
      "Generated:\teq ##ui ##pm ##ent 这 款 衬 衫 利 用 扭 结 设 计 塑 造 丰 富 的 视 觉 效 果 ， 轻 松 为 你 的 造 型 增 添 优 雅 一 笔 。 \n",
      "Target:\tvi ##nce 这 款 真 丝 缎 面 上 衣 质 感 柔 滑 ， 扭 结 衣 领 加 强 了 单 品 的 柔 美 气 息 ， 充 分 释 放 你 的 简 约 优 雅 格 调 。 \n",
      "Source:\t变 效 果 羊 绒 针 织 围 巾 \n",
      "Generated:\t羊 绒 质 感 柔 软 轻 盈 ， 保 暖 性 甚 佳 ， 是 珍 贵 稀 少 的 纺 织 原 料 ， 因 而 拥 有 [UNK] 软 黄 金 [UNK] 的 美 誉 。 eq ##ui ##l 以 此 打 造 这 款 针 织 衫 ， 为 你 带 来 时 尚 舒 \n",
      "Target:\tjan ##av ##i 这 款 围 巾 以 柔 软 细 腻 的 羊 绒 面 料 针 织 而 成 ， 渐 变 效 果 带 来 几 分 艺 术 气 息 ， 轻 松 彰 显 简 约 摩 登 之 美 。 \n",
      "Source:\t##rs ##on 闪 粉 厚 底 运 动 鞋 \n",
      "Generated:\tgolden ##go ##ose 这 款 运 动 鞋 采 用 银 色 闪 粉 及 银 色 皱 感 真 皮 制 作 ， 为 你 的 休 闲 造 型 注 入 几 分 个 性 。 \n",
      "Target:\tpe ##dr ##og ##ar ##cia 擅 长 将 休 闲 及 优 雅 风 格 融 为 一 体 。 这 款 厚 底 运 动 鞋 满 布 粉 色 闪 粉 ， 瞬 间 为 你 的 造 型 注 入 俏 丽 甜 美 一 笔 。 \n",
      "Source:\t光 细 节 水 洗 尼 龙 长 裤 \n",
      "Generated:\tthe ##up ##side 这 款 深 绿 色 长 裤 采 用 富 有 质 感 的 粒 面 料 制 作 ， 令 你 的 身 形 更 显 修 长 优 美 。 不 妨 搭 配 同 色 系 的 休 闲 裤 ， 打 造 个 性 休 闲 造 型 。 \n",
      "Target:\ttb ##ya ##lex ##and ##er ##wang 这 款 尼 龙 长 裤 经 水 洗 处 理 后 呈 现 出 做 旧 效 果 ， 结 合 <unk> 反 光 细 节 ， 为 你 的 运 动 风 造 型 渲 染 80 年 代 的 复 古 色 彩 。 \n",
      "Source:\t纹 印 花 丝 混 羊 绒 围 巾 \n",
      "Generated:\t羊 绒 质 感 柔 软 轻 盈 ， 保 暖 性 甚 佳 ， 是 珍 贵 稀 少 的 纺 织 原 料 ， 因 而 拥 有 [UNK] 软 黄 金 [UNK] 的 美 誉 。 eq ##ui ##l 以 此 打 造 这 款 针 织 衫 ， 为 你 带 来 时 尚 舒 \n",
      "Target:\t动 物 纹 理 今 季 强 势 回 归 时 尚 舞 台 ， i . s . studio 这 款 丝 混 羊 绒 围 巾 柔 软 舒 适 ， 通 身 点 缀 了 狂 野 的 豹 纹 ， 为 你 的 造 型 增 添 吸 睛 一 笔 。 \n",
      "Source:\t石 18k 金 开 口 菱 形 项 链 \n",
      "Generated:\tba ##ob ##ao ##wan 这 款 18k 金 项 链 雕 琢 出 一 只 奶 嘴 造 型 ， 充 满 可 爱 童 趣 。 镶 嵌 的 钻 石 更 添 熠 熠 熠 熠 熠 熠 生 辉 ， 令 你 的 造 型 更 具 个 性 。 \n",
      "Target:\t创 办 仅 短 短 两 年 时 间 ， ci ##ga ##lon ##g 已 经 收 获 了 众 多 明 星 粉 丝 。 这 款 18k 金 项 链 廓 形 简 洁 利 落 ， 开 口 菱 形 谱 写 个 性 一 笔 ， 为 你 的 造 型 锦 上 添 花 。 \n",
      "Source:\t何 方 头 真 皮 粗 跟 踝 靴 \n",
      "Generated:\tpe ##dd ##er ##red 这 款 踝 靴 采 用 富 有 建 筑 美 感 的 粗 跟 ， 切 割 设 计 增 添 几 分 摩 登 玩 味 ， 轻 松 升 级 你 的 摩 登 造 型 。 \n",
      "Target:\t韩 国 鞋 履 品 牌 re ##ike ##ne ##n <unk> 爱 富 建 筑 美 感 的 设 计 ， 这 款 白 色 小 山 羊 皮 踝 靴 清 新 明 亮 ， 几 何 方 头 与 圆 柱 形 粗 跟 相 互 呼 应 ， 为 简 约 款 式 注 入 摩 登 个 性 。 \n",
      "Source:\t##town 粒 面 小 牛 皮 风 <unk> 包 \n",
      "Generated:\tst ##ra ##th ##berry 这 款 east / west ##st ##y ##list 真 皮 手 拿 包 廓 形 小 巧 精 致 ， 简 洁 白 色 调 搭 配 同 色 系 列 的 红 色 调 ， 轻 松 为 你 的 造 型 画 龙 点 睛 。 \n",
      "Target:\tmark ##cr ##os ##s 将 品 牌 特 色 的 箱 型 轮 廓 融 入 这 款 风 琴 包 ， 营 造 出 复 古 质 感 。 金 色 配 件 与 红 色 小 牛 皮 主 体 交 相 辉 映 ， 别 具 优 雅 奢 华 感 觉 ， 充 分 展 现 你 的 非 凡 品 位 。 \n",
      "Source:\t##lab ##ella 迷 你 链 条 托 特 包 \n",
      "Generated:\tst ##au ##d 这 款 品 牌 热 卖 的 shi ##rley ##p ##vc 托 特 包 采 用 色 皱 感 真 皮 制 作 ， 深 蓝 色 设 计 清 新 素 雅 ， 为 你 的 造 型 增 添 时 尚 玩 味 。 \n",
      "Target:\tfa ##lab ##ella 是 st ##ella ##mc ##car ##t ##ney （ 丝 黛 拉 麦 卡 妮 ） 畅 销 的 款 式 之 一 ， 这 款 托 特 包 采 用 环 保 合 成 皮 革 打 造 出 立 体 廓 形 ， 金 属 链 条 带 来 个 性 一 笔 ， 是 打 造 日 常 摩 登 造 型 的 实 用 之 选 。 \n",
      "Source:\t##rn ##n 花 卉 蕾 丝 丁 字 裤 \n",
      "Generated:\tagent ##pro ##vo ##cat ##e ##ur 这 款 fe ##li ##tz ##ia 丁 字 裤 采 用 丝 滑 的 缎 面 面 料 制 作 ， 并 点 缀 的 黑 色 蝴 蝶 结 ， 为 单 品 增 添 浪 漫 柔 美 感 觉 。 \n",
      "Target:\tagent ##pro ##vo ##cat ##e ##ur 的 fe ##rn ##n 系 列 将 浪 漫 天 蓝 色 与 细 腻 黎 巴 蕾 丝 巧 妙 结 合 ， 碰 撞 出 清 新 又 性 感 的 视 觉 效 果 。 这 款 丁 字 裤 以 橙 黄 色 缎 面 蝴 蝶 结 增 添 俏 丽 一 笔 ， 令 你 的 造 型 冲 破 平 凡 。 \n",
      "Source:\t色 细 节 混 羊 绒 针 织 衫 \n",
      "Generated:\t羊 绒 质 感 柔 软 轻 盈 ， 保 暖 性 甚 佳 ， 是 珍 贵 稀 少 的 纺 织 原 料 ， 因 而 拥 有 [UNK] 软 黄 金 [UNK] 的 美 誉 。 eq ##ui ##l 以 此 打 造 这 款 针 织 衫 ， 为 你 带 来 时 尚 舒 \n",
      "Target:\t全 针 织 品 牌 i - am - chen 是 2018 / <unk> 国 际 羊 毛 标 志 大 奖 香 港 半 <unk> 赛 优 胜 者 ， 旨 在 让 传 统 针 织 单 品 变 得 更 加 年 轻 有 趣 。 这 款 羊 绒 针 织 衫 柔 软 细 腻 ， 拼 色 细 节 加 添 吸 睛 一 笔 ， 为 你 的 造 型 注 入 一 抹 艺 术 气 息 。 \n",
      "Source:\t##ste ##lla ##ire <unk> 金 属 圆 框 眼 镜 \n",
      "Generated:\tfor ##art ' ss ##ake 这 款 太 阳 眼 镜 采 用 金 属 打 造 出 金 属 圆 框 ， 为 你 的 造 型 增 添 吸 睛 亮 点 。 \n",
      "Target:\tchristian ##dio ##r 这 款 圆 框 眼 镜 设 计 简 约 ， 散 发 浓 郁 的 文 艺 气 息 ， 助 你 轻 松 打 造 复 古 韵 味 造 型 。 \n",
      "Source:\t##la 仿 水 晶 缎 面 搭 带 拖 鞋 \n",
      "Generated:\tpe ##dd ##er ##red 这 款 拖 鞋 采 用 缎 面 面 料 打 造 出 仿 水 晶 ， 为 你 的 休 闲 造 型 增 添 几 分 优 雅 质 感 。 \n",
      "Target:\tpe ##dr ##og ##ar ##cia 这 款 拖 鞋 的 多 重 搭 带 缀 有 闪 亮 的 施 华 洛 世 奇 仿 水 晶 ， 为 你 的 摩 登 休 闲 造 型 增 添 精 致 一 笔 。 \n",
      "Source:\t##a 仿 水 晶 绊 带 真 皮 拖 鞋 \n",
      "Generated:\tpe ##dd ##er ##red 这 款 拖 鞋 采 用 大 热 的 over ##si ##ze 廓 形 打 造 出 仿 水 晶 ， 为 你 的 休 闲 造 型 增 添 几 分 优 雅 气 息 。 \n",
      "Target:\tpe ##dd ##er ##red 这 款 真 皮 拖 鞋 采 用 清 新 怡 人 的 白 色 设 计 ， 配 合 闪 亮 迷 人 的 仿 水 晶 绊 带 ， 为 你 的 休 闲 造 型 添 上 亮 丽 一 笔 。 \n",
      "Source:\t毛 混 羊 绒 背 面 貂 毛 背 心 \n",
      "Generated:\tinn ##iu 这 款 背 心 的 背 面 的 背 面 拼 接 lo ##ro ##pi ##ana ##® 羊 毛 混 羊 绒 面 料 ， 令 廓 形 更 显 简 洁 纤 细 之 余 为 奢 华 皮 草 增 添 奢 华 气 息 。 \n",
      "Target:\tinn ##iu 这 款 貂 毛 背 心 的 背 面 拼 接 了 lo ##ro ##pi ##ana ##® 羊 毛 混 羊 绒 面 料 ， 令 廓 形 更 显 简 洁 纤 细 之 余 为 奢 华 皮 草 注 入 年 轻 时 尚 感 觉 。 \n",
      "Source:\t牌 标 志 挂 脖 吊 绳 － 黑 色 \n",
      "Generated:\tch ##lo ##e （ 蔻 依 ） 这 款 斜 挎 包 采 用 光 滑 的 缎 面 面 料 打 造 出 项 链 ， 结 合 圆 润 的 渐 变 蓝 色 金 属 圆 环 ， 为 你 的 造 型 增 添 摩 登 酷 感 。 \n",
      "Target:\t驻 扎 在 伦 敦 的 年 轻 品 牌 ch ##ao ##s 拥 有 各 式 充 满 趣 味 的 手 机 周 边 产 品 ， 这 款 吊 绳 仅 以 品 牌 标 志 作 点 缀 ， 低 调 展 露 你 的 时 尚 品 味 。 \n",
      "Source:\t褶 飘 带 微 喇 叭 高 腰 短 裤 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 短 裤 利 用 褶 [UNK] 及 抽 褶 设 计 营 造 层 次 感 及 抽 褶 细 节 营 造 出 层 次 感 ， 助 你 打 造 摩 登 休 闲 造 型 。 \n",
      "Target:\tel ##is ##sa ##mc ##go ##wan 这 款 短 裤 以 微 喇 叭 版 型 呈 现 俏 丽 感 觉 ， 整 体 设 计 清 新 素 雅 。 不 妨 利 用 抽 褶 飘 带 来 细 节 变 奏 ， 升 级 你 的 简 约 都 市 造 型 。 \n",
      "Source:\t##ga ##ux 绒 面 真 皮 粗 跟 短 靴 \n",
      "Generated:\tst ##ua ##rt ##wei ##tz ##man 的 2018 秋 冬 系 列 多 运 用 多 重 塑 经 典 单 品 ， 这 款 短 靴 采 用 富 有 质 感 的 绒 面 真 皮 制 作 ， 粗 跟 令 你 步 履 更 显 脚 踝 线 条 更 显 纤 长 ， 是 \n",
      "Target:\tgi ##an ##vi ##tor ##os ##si 这 款 短 靴 采 用 绒 面 真 皮 制 作 ， 浓 郁 饱 满 的 深 红 色 设 计 透 出 几 分 女 人 味 ， 结 合 舒 适 稳 妥 的 粗 跟 ， 是 实 穿 又 摩 登 的 理 想 单 品 。 \n",
      "Source:\t面 穿 抽 绳 连 帽 西 服 夹 克 \n",
      "Generated:\tthe ##row 这 款 西 服 外 套 采 用 温 暖 舒 适 的 深 灰 色 设 计 ， 抽 绳 腰 带 增 添 了 几 分 随 性 感 觉 ， 是 打 造 摩 登 造 型 的 理 想 单 品 。 \n",
      "Target:\tti ##bi 这 款 两 面 穿 夹 克 的 一 面 为 西 服 夹 克 造 型 ， 另 一 面 则 为 尼 龙 外 套 造 型 ， 让 你 随 心 穿 梭 于 摩 登 及 休 闲 风 格 之 间 ， 彰 显 与 众 不 同 的 时 尚 品 位 。 \n",
      "Source:\t皮 革 衣 领 格 纹 西 服 夹 克 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 西 服 夹 克 利 用 黑 色 格 纹 营 造 视 觉 变 化 ， 不 妨 搭 配 同 色 系 的 切 割 短 靴 ， 打 造 摩 登 都 市 造 型 。 \n",
      "Target:\tjune ##bo 这 款 格 纹 西 服 夹 克 充 满 浓 浓 复 古 风 情 ， 合 身 剪 裁 勾 勒 出 你 的 姣 好 身 型 ， 仿 皮 革 衣 领 则 带 出 几 分 酷 感 气 息 ， 搭 配 同 系 列 长 裤 变 身 利 落 的 都 市 造 型 。 \n",
      "Source:\t搭 叠 挖 肩 编 织 须 边 上 衣 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 上 衣 利 用 两 侧 的 罗 缎 搭 带 营 造 层 次 效 果 ， 为 你 的 造 型 增 添 几 分 性 感 魅 力 。 \n",
      "Target:\tro ##land ##mo ##ure ##t 这 款 挖 肩 上 衣 的 设 计 别 出 心 裁 ， 以 显 眼 的 编 织 格 纹 纹 理 及 搭 叠 设 计 呈 现 出 手 作 般 的 质 感 。 不 妨 搭 配 黑 色 直 脚 裤 及 高 跟 鞋 ， 一 展 经 典 摩 登 风 范 。 \n",
      "Source:\t面 穿 羊 毛 混 丝 短 款 夹 克 \n",
      "Generated:\tji ##nn ##nn 这 款 短 裤 采 用 温 暖 舒 适 的 羊 毛 混 羊 绒 面 料 制 作 ， 腰 带 来 酷 感 个 性 。 你 可 利 用 拉 链 打 造 开 衩 衣 袖 增 添 单 品 的 单 品 ， 随 性 造 型 令 人 过 \n",
      "Target:\tmin ##ki 这 件 两 面 穿 短 款 夹 克 采 用 羊 毛 混 丝 面 料 制 作 ， 一 面 为 泛 有 光 泽 的 浅 粉 色 主 体 ， 一 面 为 拼 接 了 [UNK] 缝 布 饰 的 深 蓝 色 毛 绒 质 感 面 料 ， 带 给 你 不 同 风 格 的 穿 着 体 验 。 \n",
      "Source:\t[UNK] 荷 叶 边 切 割 下 摆 半 裙 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 半 身 裙 通 身 缀 有 荷 叶 边 ， 为 单 品 增 添 几 分 现 代 感 与 摩 登 质 感 。 不 妨 搭 配 同 系 列 的 切 割 短 裤 ， 打 造 简 约 \n",
      "Target:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 半 裙 由 褶 [UNK] 荷 叶 边 拼 接 而 成 ， 塑 造 出 叠 层 般 的 视 觉 效 果 。 单 品 廓 形 丰 盈 ， 切 割 裙 摆 更 添 设 计 感 ， 是 打 造 休 闲 都 市 造 型 的 浪 漫 迷 人 之 选 。 \n",
      "Source:\t##ley 钩 编 边 饰 比 基 尼 泳 裤 \n",
      "Generated:\t土 耳 其 小 众 品 牌 k ##ii ##ni 取 名 于 bi ##kin ##i 的 简 称 ， 这 款 比 基 尼 泳 裤 以 亮 眼 的 黄 色 背 景 映 衬 多 彩 钩 编 边 饰 ， 让 你 在 沙 滩 上 散 发 阳 光 活 力 。 \n",
      "Target:\t由 土 耳 其 设 计 师 ip ##ek ##ir ##gi ##t 推 出 的 泳 装 品 牌 k ##ii ##ni 主 打 波 西 米 亚 风 格 ， 这 款 比 基 尼 泳 裤 以 深 红 色 为 基 调 ， 沿 边 点 缀 的 钩 编 边 饰 及 松 紧 带 增 添 了 色 彩 活 力 ， 同 时 保 留 了 自 身 的 沉 稳 气 息 。 \n",
      "Source:\t<unk> ##t ##45 闪 亮 丝 线 低 跟 短 靴 \n",
      "Generated:\tsam ##ed ##el ##man 这 款 袜 式 短 靴 通 身 缀 有 金 色 金 属 ， 远 看 宛 若 夜 空 的 星 光 散 发 出 光 芒 的 光 芒 。 \n",
      "Target:\ta ##q ##ua ##zz ##ura 这 款 低 跟 短 靴 采 用 闪 亮 的 <unk> 勒 克 斯 丝 线 制 作 ， 令 简 约 款 式 别 具 摩 登 未 来 感 觉 。 \n",
      "Source:\t靴 子 条 纹 印 花 真 丝 衬 衫 裙 \n",
      "Generated:\tne ##il ##bar ##re ##tt （ 尼 奥 贝 奈 特 ） 这 款 衬 衫 裙 采 用 真 丝 面 料 制 作 ， 结 合 飘 逸 的 红 色 条 纹 ， 为 单 品 增 添 几 分 复 古 质 感 。 不 妨 搭 配 同 色 系 的 短 靴 ， \n",
      "Target:\tga ##b ##rie ##la ##he ##ar ##st 这 款 米 色 真 丝 衬 衫 裙 优 雅 知 性 ， 细 看 裙 身 的 条 纹 由 一 只 只 靴 子 组 合 而 成 ， 别 具 幽 默 玩 味 。 \n",
      "Source:\t##go ##t 弹 力 天 鹅 绒 粗 跟 短 靴 \n",
      "Generated:\tst ##ua ##rt ##wei ##tz ##man 的 2018 秋 冬 系 列 多 运 用 多 运 用 多 种 色 彩 色 彩 色 彩 色 彩 粗 跟 令 这 款 短 靴 线 条 更 显 纤 细 的 纤 细 腿 部 ， 助 你 打 造 摩 登 造 型 。 \n",
      "Target:\tst ##ua ##rt ##wei ##tz ##man 以 质 感 细 腻 的 天 鹅 绒 升 级 这 款 灰 色 短 靴 ， 高 度 适 宜 的 粗 跟 让 你 步 履 稳 健 自 信 ， 充 分 彰 显 你 的 时 尚 品 位 。 \n",
      "Source:\t叶 边 立 领 褶 [UNK] 暗 开 襟 衬 衫 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 衬 衫 利 用 对 比 鲜 明 的 色 调 及 开 衩 衣 袖 营 造 出 层 次 感 ， 轻 松 升 级 你 的 摩 登 都 市 造 型 。 \n",
      "Target:\tsi ##tu ##ation ##ist 这 款 白 衬 衫 利 用 荷 叶 边 立 领 及 丰 盈 的 衣 袖 建 构 古 典 轮 廓 ， 拼 接 、 收 腰 设 计 更 添 优 雅 一 笔 ， 令 简 约 单 品 焕 然 一 新 。 \n",
      "Source:\t##jo ##ur 系 带 搭 叠 荷 叶 边 上 衣 \n",
      "Generated:\tma ##tic ##ev ##sk ##i 这 款 连 衣 裙 利 用 对 比 鲜 明 的 色 调 及 面 料 营 造 层 次 感 ， 荷 叶 边 袖 口 增 添 了 优 雅 质 感 ， 搭 配 同 色 系 的 喇 叭 裤 便 是 摩 登 十 足 的 都 市 \n",
      "Target:\trebecca ##val ##lan ##ce 这 款 上 衣 以 系 带 及 搭 叠 荷 叶 边 塑 造 出 包 裹 式 效 果 ， 整 体 设 计 清 新 优 雅 ， 不 妨 搭 配 同 色 喇 叭 裤 ， 打 造 简 洁 大 方 的 都 市 造 型 。 \n",
      "Source:\t##em ##i 车 缝 线 露 单 肩 针 织 衫 \n",
      "Generated:\tba ##len ##cia ##ga （ 巴 黎 世 家 ） 这 款 针 织 衫 采 用 明 亮 雅 致 的 蓝 绿 色 设 计 ， 背 面 的 镂 空 细 节 更 添 几 分 性 感 气 息 ， 轻 松 升 级 你 的 摩 登 休 闲 造 型 。 \n",
      "Target:\tso ##lace ##lon ##don 深 谙 如 何 利 用 剪 裁 勾 勒 出 女 性 的 魅 力 ， 这 款 露 单 肩 针 织 衫 设 计 简 洁 优 雅 ， 车 缝 线 饰 边 带 来 几 分 随 性 气 息 ， 展 现 你 的 时 尚 品 味 。 \n",
      "Source:\t亮 片 衣 领 扇 贝 图 案 针 织 衫 \n",
      "Generated:\tne ##il ##bar ##re ##tt （ 尼 奥 贝 奈 特 ） 这 款 针 织 衫 通 身 缀 有 金 色 亮 片 ， 为 单 品 增 添 几 分 浪 漫 浪 漫 摩 登 气 息 。 \n",
      "Target:\tva ##lent ##ino （ 华 伦 天 奴 ） 这 款 针 织 衫 以 通 身 的 扇 贝 图 纹 营 造 出 宛 若 鱼 鳞 般 的 视 觉 效 果 ， 珠 饰 亮 片 衣 领 更 添 浓 墨 重 彩 的 一 笔 ， 彰 显 你 的 不 俗 品 味 。 \n",
      "Source:\t##y ##85 小 山 羊 皮 尖 头 高 跟 鞋 \n",
      "Generated:\tsam ##ed ##el ##man 这 款 高 跟 鞋 采 用 黑 色 绒 面 真 皮 制 造 ， 高 度 适 中 的 粗 跟 令 你 步 履 更 显 纤 长 ， 是 打 造 摩 登 造 型 的 理 想 单 品 。 \n",
      "Target:\tjimmy ##ch ##oo 这 款 高 跟 鞋 设 计 简 约 ， 采 用 光 滑 柔 软 的 小 山 羊 皮 制 作 ， 结 合 尖 头 设 计 ， 衬 托 出 您 修 长 纤 细 的 双 腿 ， 不 论 是 点 缀 日 常 或 都 市 造 型 都 优 雅 大 方 。 \n",
      "Source:\t##ro ##ub ##le 亮 片 对 话 框 针 织 衫 \n",
      "Generated:\t为 庆 祝 2018 <unk> 周 年 ， 品 牌 ba ##len ##cia ##ga （ 巴 黎 世 家 ） 这 款 针 织 衫 以 黑 色 亮 片 为 单 品 增 添 浪 漫 神 秘 色 彩 ， 令 你 的 造 型 更 具 个 性 。 \n",
      "Target:\talice + ol ##i ##via 这 款 黑 色 针 织 衫 以 密 密 麻 麻 的 亮 片 组 合 出 对 话 框 及 英 文 字 t ##ro ##ub ##le ， 轻 轻 一 扫 框 中 文 字 便 可 切 换 成 [UNK] <unk> ##me <unk> [UNK] 标 语 ， 为 你 的 造 型 注 入 时 尚 玩 味 。 \n",
      "Source:\t##el ##in 仿 水 晶 铆 钉 缎 面 拖 鞋 \n",
      "Generated:\tpe ##dd ##er ##red 这 款 拖 鞋 采 用 大 热 的 over ##si ##ze 廓 形 打 造 出 仿 水 晶 ， 为 你 的 休 闲 造 型 增 添 一 抹 优 雅 气 息 。 \n",
      "Target:\tpe ##dr ##og ##ar ##cia 这 款 拖 鞋 采 用 丝 滑 的 浅 灰 色 缎 面 面 料 打 造 搭 带 ， 并 点 缀 精 美 的 银 色 施 华 洛 世 奇 仿 水 晶 铆 钉 ， 为 休 闲 款 式 增 添 一 抹 华 丽 气 息 ， 是 时 尚 又 实 穿 的 百 搭 单 品 。 \n",
      "Source:\t##nd ##ola 蝴 蝶 结 衣 袖 挖 肩 衬 衫 \n",
      "Generated:\tso ##nia ##ry ##ki ##el 这 款 衬 衫 以 立 领 的 蝴 蝶 结 及 肩 带 来 细 节 感 ， 为 你 的 造 型 注 入 几 分 女 人 味 。 \n",
      "Target:\tle ##ald ##ac ##care ##tt 灵 活 运 用 蝴 蝶 结 装 饰 ， 为 都 市 服 饰 带 来 惊 喜 变 奏 。 这 款 衬 衫 以 此 配 合 挖 剪 镂 空 细 节 ， 独 特 的 衣 袖 轻 松 抓 人 眼 球 ， 同 时 提 升 了 单 品 的 廓 形 感 ， 彰 显 你 与 众 不 同 的 时 尚 品 位 。 \n",
      "Source:\t双 色 钻 石 18k 白 金 开 口 手 镯 \n",
      "Generated:\tof ##ee 的 设 计 充 满 简 约 优 雅 的 法 式 情 调 。 这 款 手 镯 采 用 18k 金 打 造 ， 简 洁 纤 细 的 链 条 随 风 摇 曳 摆 动 ， 让 你 的 举 手 投 足 间 展 现 灵 动 美 感 。 \n",
      "Target:\tce ##nt ##au ##ri ##lu ##cy 甄 选 澳 大 利 亚 出 产 的 天 然 彩 色 钻 石 打 造 classic 系 列 ， 现 代 、 优 雅 而 简 洁 的 设 计 风 格 十 分 适 合 日 常 佩 戴 。 这 款 手 镯 以 18k 白 金 打 造 出 纤 细 的 开 口 款 式 ， 两 端 各 点 缀 一 颗 小 巧 精 致 的 钻 石 ， 无 论 叠 搭 或 单 独 配 搭 都 摩 登 动 人 。 \n",
      "Source:\t##w ##l 钻 石 18k 白 金 猫 头 <unk> 项 链 \n",
      "Generated:\tba ##ob ##ao ##wan 这 款 18k 金 项 链 雕 琢 出 一 只 奶 嘴 造 型 ， 充 满 浪 漫 柔 美 气 息 。 镶 嵌 的 钻 石 更 添 熠 熠 熠 熠 光 芒 ， 为 你 的 造 型 增 添 神 秘 色 彩 。 \n",
      "Target:\tba ##ob ##ao ##wan 这 款 18k 白 金 猫 头 鹰 项 链 小 巧 精 致 ， 黑 白 色 钻 石 勾 勒 出 可 爱 的 [UNK] 黑 夜 使 者 [UNK] ， 为 你 的 造 型 画 龙 点 睛 。 \n",
      "Source:\t##lly 品 牌 标 志 翻 领 羊 毛 针 织 衫 \n",
      "Generated:\tac ##nes ##tu ##dio ##s 这 款 针 织 衫 采 用 柔 软 舒 适 的 羊 毛 面 料 制 作 ， 深 蓝 色 条 纹 为 单 品 增 添 几 分 摩 登 质 感 ， 是 打 造 简 约 休 闲 造 型 的 理 想 单 品 。 \n",
      "Target:\tis ##ab ##el ##mar ##ant ##et ##oi ##le 这 款 宝 蓝 色 针 织 衫 由 不 同 针 织 纹 理 构 成 ， 款 式 简 约 却 不 失 细 节 感 ， 充 分 展 现 设 计 师 的 细 腻 巧 思 。 \n",
      "Source:\t##na 品 牌 名 称 衣 领 over ##si ##ze 卫 衣 \n",
      "Generated:\tac ##nes ##tu ##dio ##s 这 款 over ##si ##ze 短 款 over ##si ##ze 卫 衣 采 用 舒 适 柔 软 的 浅 粉 色 设 计 ， 助 你 打 造 刚 柔 并 济 的 休 闲 造 型 。 \n",
      "Target:\tover ##si ##ze 上 衣 是 打 造 酷 感 街 头 造 型 的 热 门 单 品 。 ac ##nes ##tu ##dio ##s 这 款 卫 衣 于 衣 领 点 缀 品 牌 名 称 ， 是 简 约 舒 适 且 具 辨 识 度 的 款 式 。 \n",
      "Source:\t心 狐 毛 口 袋 斗 篷 式 羊 毛 大 衣 \n",
      "Generated:\tinn ##iu 这 款 貂 毛 背 心 的 背 面 拼 接 了 lo ##ro ##pi ##ana ##® 羊 毛 混 羊 绒 面 料 ， 令 廓 形 更 显 简 洁 纤 细 之 余 为 奢 华 皮 草 注 入 年 轻 时 尚 玩 味 。 \n",
      "Target:\tfe ##ndi 这 款 羊 毛 大 衣 剪 裁 流 畅 ， 爱 心 图 案 狐 毛 口 袋 带 来 辨 识 度 与 奢 华 气 息 ， 搭 配 宛 若 斗 篷 式 的 宽 大 衣 袖 ， 助 你 打 造 优 雅 秋 冬 造 型 。 \n",
      "Source:\t##er 人 造 珍 珠 搭 叠 设 计 连 衣 裙 \n",
      "Generated:\tdi ##on ##lee 这 款 连 衣 裙 采 用 双 层 设 计 ， 人 造 珍 珠 与 金 属 缀 饰 带 来 几 分 几 分 摩 登 玩 味 ， 助 你 打 造 刚 柔 并 济 的 都 市 造 型 。 \n",
      "Target:\tsan ##dy ##lia ##ng 这 款 白 色 连 衣 裙 <unk> 巧 可 爱 ， 正 面 的 搭 叠 设 计 低 调 增 添 了 单 品 的 层 次 感 ， 配 以 一 排 斜 向 人 造 珍 珠 ， 轻 松 衬 托 出 你 的 淑 女 风 范 。 \n",
      "Source:\t带 设 计 刺 绣 薄 纱 深 v 连 衣 裙 \n",
      "Generated:\tne ##ed ##le & amp ; thread 这 款 连 衣 裙 通 身 缀 有 由 亮 片 组 成 的 花 卉 刺 绣 ， 为 单 品 增 添 几 分 浪 漫 浪 漫 浪 漫 柔 美 气 息 。 不 妨 搭 配 白 色 上 衣 及 黑 色 短 靴 ， \n",
      "Target:\tself - port ##ra ##it 这 款 连 衣 裙 在 蓝 灰 色 裙 身 搭 叠 了 一 层 珠 饰 刺 绣 薄 纱 ， 营 造 朦 胧 美 感 。 前 后 深 v 领 设 计 更 添 性 感 魅 力 ， 令 你 的 造 型 愈 发 优 雅 迷 人 。 \n",
      "Source:\t##ise ##e - v 三 重 尼 龙 搭 带 凉 鞋 \n",
      "Generated:\tsam ##ed ##el ##man 这 款 拖 鞋 以 金 色 金 属 打 造 出 对 称 的 英 文 字 母 带 来 几 分 复 古 质 感 ， 轻 松 升 级 你 的 休 闲 造 型 。 \n",
      "Target:\tsui ##co ##ke 这 款 凉 鞋 采 用 夹 棉 尼 龙 打 造 搭 带 ， 结 合 防 滑 耐 磨 的 vi ##bra ##m ##® 鞋 底 ， 穿 着 倍 感 舒 适 合 腳 。 橄 榄 绿 色 设 计 率 性 硬 朗 ， 是 日 常 外 出 的 理 想 休 闲 鞋 款 。 \n",
      "Source:\t##ist ##on 高 领 美 丽 诺 羊 毛 针 织 衫 \n",
      "Generated:\ti - am - chen 着 迷 于 色 彩 的 游 戏 ， 其 2018 秋 冬 系 列 名 为 [UNK] 色 彩 炸 弹 [UNK] ， 灵 感 源 自 野 兽 派 画 家 and ##red ##era ##in 的 早 期 画 作 。 这 款 美 丽 诺 羊 毛 针 织 衫 以 \n",
      "Target:\tcanada ##go ##ose 这 款 黑 色 高 领 针 织 衫 采 用 柔 软 亲 肤 的 美 丽 诺 羊 毛 面 料 制 造 ， the ##rma ##lm ##app ##ing ##® 技 术 加 强 了 单 品 的 透 气 度 ， 让 你 穿 着 时 倍 感 舒 适 ， 是 秋 冬 常 备 的 实 穿 款 式 。 \n",
      "Source:\t钉 金 属 片 粗 跟 真 皮 切 尔 西 靴 \n",
      "Generated:\talexander ##wang （ 亚 历 山 大 王 ） 这 款 真 皮 切 割 粗 跟 短 靴 线 条 流 畅 ， 金 属 铆 钉 增 添 酷 感 酷 感 酷 感 酷 感 气 息 ， 轻 松 升 级 你 的 摩 登 都 市 造 型 。 \n",
      "Target:\talexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 这 款 真 皮 切 尔 西 靴 廓 形 简 洁 硬 朗 ， 后 部 的 一 抹 红 色 带 来 鲜 明 层 次 变 化 ， 鞋 跟 上 的 铆 钉 金 属 贴 片 更 增 酷 感 气 息 ， 为 你 的 造 型 增 添 个 性 一 笔 。 \n",
      "Source:\t##ing 弹 力 绒 面 真 皮 小 猫 跟 短 靴 \n",
      "Generated:\tst ##ua ##rt ##wei ##tz ##man 的 2018 秋 冬 系 列 多 运 用 品 牌 的 建 筑 美 感 ， 这 款 短 靴 采 用 富 有 弹 性 的 绒 面 真 皮 制 作 ， 结 合 稳 妥 的 粗 跟 ， 助 你 轻 松 打 造 摩 登 造 型 \n",
      "Target:\tst ##ua ##rt ##wei ##tz ##man 这 款 绒 面 真 皮 短 靴 由 gigi ##ha ##di ##d 钟 爱 的 cl ##ing ##er 系 列 变 奏 而 成 ， 红 色 设 计 十 分 抓 人 眼 球 ， 纤 细 的 小 猫 跟 令 廓 形 更 流 畅 利 落 ， 无 论 搭 配 裤 装 或 裙 装 都 能 散 发 摩 登 女 人 味 。 \n",
      "Source:\t状 布 饰 不 对 称 真 丝 缎 面 长 裤 \n",
      "Generated:\tthe ##row 这 款 深 蓝 色 长 裤 采 用 缎 面 面 料 制 作 ， 长 长 长 长 长 长 长 裤 腿 的 侧 条 带 来 几 分 随 性 感 觉 ， 是 打 造 摩 登 休 闲 造 型 的 理 想 单 品 。 \n",
      "Target:\tdi ##on ##lee 这 款 长 裤 采 用 柔 顺 轻 盈 的 桑 蚕 丝 缎 面 面 料 精 心 剪 裁 ， 不 对 称 门 襟 设 计 呈 现 出 玩 味 的 廓 形 变 奏 。 裤 腿 的 白 色 条 状 布 饰 增 添 几 分 运 动 风 情 ， 搭 配 白 色 罗 纹 针 织 衫 及 短 靴 便 是 摩 登 休 闲 造 型 。 \n",
      "Source:\t钉 人 造 珍 珠 点 缀 真 皮 乐 福 鞋 \n",
      "Generated:\tsam ##ed ##el ##man 这 款 乐 福 鞋 采 用 黑 色 真 皮 打 造 出 对 比 色 彩 ， 金 属 圆 环 带 来 几 分 复 古 摩 登 感 觉 ， 轻 松 升 级 你 的 摩 登 休 闲 造 型 。 \n",
      "Target:\t想 要 打 造 斯 文 复 古 造 型 ， 不 妨 选 择 古 驰 这 款 乐 福 鞋 ， 鞋 面 点 缀 的 金 属 gg 缀 饰 和 拼 色 条 纹 搭 带 颇 具 辨 识 度 ， 与 鞋 跟 的 铆 钉 及 人 造 珍 珠 相 映 衬 ， 散 发 浓 郁 怀 旧 气 息 。 你 可 随 意 转 换 为 包 跟 或 露 跟 款 式 穿 着 ， 为 造 型 增 添 休 闲 风 格 。 \n",
      "Source:\t##se ##lla 切 割 设 计 荔 枝 纹 真 皮 拖 鞋 \n",
      "Generated:\tsam ##ed ##el ##man 这 款 拖 鞋 以 金 色 真 皮 打 造 出 对 称 的 英 文 字 母 带 来 几 分 现 代 几 何 美 感 ， 轻 松 升 级 你 的 休 闲 造 型 。 \n",
      "Target:\tmar ##se ##ll 的 鞋 履 以 简 约 实 用 见 称 。 这 款 拖 鞋 采 用 切 割 设 计 为 款 式 带 来 几 何 美 感 ， 充 分 展 现 你 的 摩 登 个 性 。 \n",
      "Source:\t##ma 金 属 环 系 带 混 丝 高 腰 露 踝 裤 \n",
      "Generated:\teq ##ui ##pm ##ent 这 款 露 踝 裤 利 用 双 排 扣 营 造 丰 富 的 层 次 感 ， 深 浅 色 调 的 双 排 扣 增 添 了 细 节 感 ， 轻 松 升 级 你 的 摩 登 都 市 造 型 。 \n",
      "Target:\tpet ##ar ##pe ##tro ##v 这 款 混 丝 高 腰 露 踝 裤 线 条 流 畅 利 落 ， 腰 间 的 金 属 环 系 带 加 添 摩 登 一 笔 ， 是 百 搭 又 不 失 设 计 感 的 单 品 。 \n",
      "Source:\t<unk> ##a 绑 带 花 卉 点 缀 蕾 丝 三 角 裤 \n",
      "Generated:\tagent ##pro ##vo ##cat ##e ##ur 这 款 fe ##li ##tz ##ia 三 角 裤 采 用 丝 滑 的 缎 面 面 料 制 作 ， 并 点 缀 的 黑 色 缎 面 绑 带 ， 宛 若 捆 绑 式 的 视 觉 效 果 令 人 热 血 沸 腾 。 \n",
      "Target:\tagent ##pro ##vo ##cat ##e ##ur 这 款 at <unk> ##a 三 角 裤 以 网 状 弹 力 绑 带 塑 造 独 特 性 感 风 格 ， 配 以 纯 白 的 花 卉 缀 饰 和 蕾 丝 细 节 ， 助 你 绽 放 迷 人 魅 力 。 \n",
      "Source:\t##mo ##sa 深 v 领 挖 剪 露 背 <unk> 地 长 裙 \n",
      "Generated:\tne ##il ##bar ##re ##tt （ 尼 奥 贝 奈 特 ） 这 款 连 衣 裙 采 用 [UNK] 绸 面 料 制 作 ， 两 侧 的 罗 缎 抽 褶 带 来 几 分 复 古 质 感 ， 助 你 打 造 摩 登 都 市 造 型 。 \n",
      "Target:\trebecca ##val ##lan ##ce 这 款 深 蓝 色 连 衣 裙 以 深 v 领 呼 应 背 面 的 镂 空 挖 剪 ， 为 单 品 注 入 妩 媚 女 人 味 。 曳 地 长 度 气 场 十 足 ， 令 你 在 聚 会 中 脱 颖 而 出 。 \n",
      "Source:\t拆 式 衣 领 及 套 指 袖 口 短 款 夹 克 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 短 款 夹 克 利 用 对 比 鲜 明 的 色 设 计 营 造 出 层 次 对 比 ， 两 件 长 款 式 则 有 助 修 饰 你 的 身 型 比 例 ， 是 时 尚 实 用 \n",
      "Target:\tph ##v ##lo 擅 长 运 用 可 拆 式 设 计 打 造 令 人 惊 喜 的 解 构 服 饰 。 这 件 夹 克 以 搭 叠 衣 领 及 深 蓝 色 套 指 袖 口 带 来 层 次 变 化 ， 瞬 间 提 升 简 约 单 品 的 设 计 感 。 \n",
      "Source:\t线 缠 绕 海 星 吊 坠 珠 饰 夹 耳 耳 环 \n",
      "Generated:\tos ##card ##el ##are ##nt ##a 这 款 耳 环 以 金 色 金 属 打 造 出 渐 变 蓝 色 珠 饰 ， 为 你 的 造 型 增 添 几 分 浪 漫 浪 漫 柔 美 气 息 。 \n",
      "Target:\tos ##card ##el ##are ##nt ##a 将 各 式 海 洋 生 物 化 作 精 美 首 饰 ， 这 款 黑 色 夹 耳 耳 环 缀 有 一 个 丝 线 缠 绕 的 海 星 吊 坠 ， 配 合 晶 亮 的 珠 饰 ， 为 你 的 造 型 注 入 几 分 亮 眼 玩 味 。 \n",
      "Source:\t##ric ##an ##cam ##o 几 何 图 案 四 面 弹 夹 克 \n",
      "Generated:\tthe ##up ##side 这 款 背 心 采 用 富 有 质 感 的 四 面 弹 面 料 制 作 ， 令 你 穿 着 倍 感 舒 适 。 几 何 提 花 边 增 添 了 几 分 随 性 感 觉 ， 是 简 约 实 用 的 实 用 常 常 备 单 品 \n",
      "Target:\tthe ##up ##side 这 款 四 面 弹 夹 克 通 身 缀 有 启 发 自 非 洲 文 化 及 迷 彩 纹 理 的 几 何 图 案 ， 营 造 动 感 活 力 之 余 带 有 几 分 八 十 年 代 味 道 ， 让 你 毫 不 费 力 地 展 现 摩 登 运 动 风 范 。 \n",
      "Source:\t##ba ##g <unk> 粒 面 山 羊 皮 箱 型 斜 挎 包 \n",
      "Generated:\tmark ##cr ##os ##s 从 grace ##ke ##ke ##ini ##no ##mi ##ya 的 包 袋 ， 其 绿 色 箱 为 灵 感 打 造 出 grace 箱 型 包 袋 ， 这 款 箱 型 单 肩 包 。 配 以 银 色 金 属 配 件 ， 为 你 的 造 型 增 添 吸 睛 亮 \n",
      "Target:\talexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 这 款 经 典 的 箱 型 斜 挎 包 灵 感 来 自 古 董 行 李 箱 ， 选 用 黑 色 粒 面 山 羊 皮 打 造 出 精 致 轮 廓 ， 配 以 耀 眼 的 金 色 链 条 手 提 带 ， 轻 松 俘 虏 女 士 芳 心 。 \n",
      "Source:\t瑰 印 花 拼 色 条 纹 缎 面 <unk> 服 外 套 \n",
      "Generated:\tthe ##up ##side 这 款 西 服 外 套 的 背 面 拼 色 条 ， 为 单 品 增 添 几 分 复 古 质 感 。 不 妨 搭 配 同 色 系 的 条 纹 衬 衫 及 黑 色 短 靴 ， 打 造 摩 登 都 市 造 型 。 \n",
      "Target:\tgucci （ 古 驰 ） 这 款 外 套 受 日 本 和 服 影 响 ， 呈 现 出 宽 松 的 日 式 廓 形 。 娇 艳 的 玫 瑰 印 花 缀 满 缎 面 表 层 ， 为 单 品 增 添 了 春 日 暖 意 。 配 以 品 牌 经 典 的 红 蓝 拼 色 条 纹 ， 轻 松 升 级 你 的 整 体 造 型 。 \n",
      "Source:\t##lab ##ella 迷 你 鹿 纹 纹 理 链 条 托 特 包 \n",
      "Generated:\tst ##au ##d 这 款 品 牌 热 卖 的 shi ##rley ##p ##vc 托 特 包 采 用 色 绒 面 真 皮 制 作 ， 质 感 与 色 彩 对 比 营 造 出 几 分 未 来 感 ， 轻 松 为 你 的 造 型 画 龙 点 睛 。 \n",
      "Target:\tfa ##lab ##ella 是 st ##ella ##mc ##car ##t ##ney （ 丝 黛 拉 麦 卡 妮 ） 的 畅 销 款 式 之 一 ， 这 款 泛 有 淡 淡 光 泽 的 黑 色 托 特 包 采 用 环 保 合 成 皮 革 制 造 ， 鹿 纹 纹 理 塑 造 出 独 特 质 感 ， 结 合 别 具 辨 识 度 的 链 条 边 饰 及 肩 带 ， 衬 托 你 的 俏 丽 风 姿 。 \n",
      "Source:\t<unk> ##you ##r <unk> ##s ##18 ##k 白 金 <unk> 子 缀 饰 \n",
      "Generated:\tj . cr ##ick ##et 这 款 项 链 以 纯 棉 面 料 打 造 出 丰 富 的 层 次 感 与 质 感 的 项 链 。 吊 坠 上 隐 若 可 见 的 出 你 可 见 的 脸 型 ， 随 风 摇 曳 摆 动 ， 让 你 于 举 手 投 \n",
      "Target:\tlo ##que ##tl ##ond ##on 善 于 将 富 有 含 义 的 元 素 注 入 首 饰 设 计 ， 令 每 件 单 品 更 具 象 征 性 及 故 事 性 。 这 款 缀 饰 以 18k 白 金 打 造 出 寓 意 [UNK] 自 由 <unk> <unk> [UNK] 的 <unk> 子 造 型 。 你 可 选 择 单 独 放 于 吊 坠 盒 内 ， 或 与 其 它 缀 饰 组 合 ， 是 个 人 订 制 或 馈 赠 亲 友 的 别 致 之 选 。 \n",
      "Source:\t##st ##ud 小 号 铆 钉 [UNK] 缝 小 羊 皮 斜 挎 包 \n",
      "Generated:\tva ##lent ##ino ##gar ##av ##ani 这 款 斜 挎 包 采 用 黑 色 真 皮 制 作 ， 金 色 铆 钉 宛 若 星 星 星 星 星 闪 烁 于 深 蓝 色 的 铆 钉 宛 若 夜 空 的 星 星 星 星 ， 为 你 的 造 型 增 添 酷 感 \n",
      "Target:\tva ##lent ##ino ##gar ##av ##ani 以 标 志 性 的 锥 形 铆 钉 打 造 出 这 款 [UNK] 缝 小 羊 皮 斜 挎 包 ， 浅 粉 色 设 计 素 净 淡 雅 ， 轻 松 彰 显 你 的 时 尚 个 性 。 \n",
      "Source:\t##ure ##en 双 重 镜 面 搭 带 天 鹅 绒 穆 勒 鞋 \n",
      "Generated:\tsam ##ed ##el ##man 这 款 金 色 金 属 搭 带 凉 鞋 简 约 ， 轻 松 为 你 的 休 闲 造 型 增 添 几 分 复 古 气 息 。 \n",
      "Target:\tma ##lone ##so ##ul ##ier ##s 以 银 色 双 重 镜 面 搭 带 映 衬 这 款 深 蓝 色 天 鹅 绒 穆 勒 鞋 ， 流 线 型 鞋 身 贴 合 你 的 脚 部 线 条 ， 轻 松 带 来 静 谧 优 雅 之 感 。 \n",
      "Source:\t星 刺 绣 over ##si ##ze 牛 仔 连 帽 派 克 大 衣 \n",
      "Generated:\tac ##nes ##tu ##dio ##s 这 款 连 帽 夹 克 以 深 浅 色 调 呈 现 出 几 何 美 感 ， over ##si ##ze 版 型 令 你 穿 着 倍 感 舒 适 。 不 妨 搭 配 同 色 系 列 休 闲 裤 ， 打 造 简 约 摩 登 的 休 闲 \n",
      "Target:\tet ##re ##ce ##cil ##e 以 over ##si ##ze 剪 裁 加 强 这 款 牛 仔 派 克 大 衣 的 休 闲 感 觉 ， 不 同 形 状 的 星 星 刺 绣 则 带 来 几 分 个 性 玩 味 ， 充 分 展 现 你 的 随 性 魅 力 。 \n",
      "Source:\t##tter 纹 理 金 箔 不 规 则 吊 坠 金 属 耳 环 \n",
      "Generated:\tken ##net ##h ##ja ##y ##lan ##e 这 款 耳 环 采 用 镀 银 金 属 打 造 出 ， 纤 细 的 镀 金 金 属 链 条 为 单 品 增 添 几 分 现 代 艺 术 美 感 ， 轻 松 升 级 你 的 摩 登 都 市 造 型 。 \n",
      "Target:\te ##jing ##z ##hang 的 珠 宝 作 品 中 处 处 可 见 大 自 然 山 水 的 影 子 ， 这 款 耳 环 以 三 个 如 同 宝 石 一 般 的 不 规 则 吊 坠 带 来 清 新 灵 动 之 感 ， 为 你 的 造 型 锦 上 添 花 。 \n",
      "Source:\t边 流 苏 混 羊 毛 及 亚 麻 高 腰 阔 腿 裤 \n",
      "Generated:\tne ##il ##bar ##re ##tt （ 尼 奥 贝 奈 特 ） 这 款 高 腰 阔 腿 裤 采 用 高 腰 及 喇 叭 裤 腿 营 造 出 宛 若 裙 般 的 罗 缎 ， 为 你 的 造 型 注 入 几 分 女 人 味 。 \n",
      "Target:\tu ##ma ##wang ##20 ##18 秋 冬 系 列 于 巴 黎 时 装 周 拉 开 <unk> <unk> ， 弥 漫 着 浪 漫 复 古 氛 围 。 这 款 高 腰 阔 腿 裤 以 大 片 的 须 边 流 苏 营 造 颓 废 感 觉 ， 彰 显 你 独 具 一 格 的 时 尚 态 度 。 \n",
      "Source:\t华 洛 世 奇 仿 水 晶 骷 髅 头 圆 形 耳 环 \n",
      "Generated:\talexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 这 款 耳 环 采 用 光 滑 细 腻 的 小 牛 皮 制 作 ， 深 浅 色 骷 髅 头 指 环 扣 仿 如 精 美 的 骷 髅 头 造 型 ， 为 你 的 造 型 画 龙 点 睛 。 \n",
      "Target:\talexander ##mc ##que ##en （ 亚 历 山 大 麦 昆 ） 将 标 志 性 的 骷 髅 头 融 入 配 饰 设 计 之 中 。 这 款 圆 形 耳 环 以 此 作 点 睛 之 笔 ， 配 以 闪 烁 的 施 华 洛 世 奇 仿 水 晶 ， 为 你 的 造 型 注 入 个 性 亮 点 。 \n",
      "Source:\t##sa ##b ##lan ##ca 豹 纹 提 花 混 羊 毛 针 织 衫 \n",
      "Generated:\tac ##nes ##tu ##dio ##s 这 款 针 织 衫 采 用 柔 软 细 腻 的 深 浅 色 调 ， 为 单 品 增 添 几 分 浪 漫 艺 术 色 彩 。 不 妨 搭 配 浅 色 调 及 短 靴 ， 打 造 个 性 休 闲 造 型 。 \n",
      "Target:\t在 alt ##u ##za ##rr ##a （ 奥 图 扎 拉 ） 的 2018 早 秋 画 报 中 ， 豹 纹 元 素 随 处 可 见 。 这 款 针 织 衫 点 缀 了 一 圈 启 发 自 土 耳 其 传 统 编 织 k ##il ##im 地 毯 的 曲 形 图 案 ， 为 单 品 注 入 几 分 民 族 风 气 息 。 \n",
      "Source:\t##cl ##ub ##1 品 牌 名 称 提 花 透 明 遮 阳 帽 \n",
      "Generated:\tdior （ 迪 奥 ） 这 款 飞 行 员 太 阳 眼 镜 的 黄 色 品 牌 名 称 ， 以 具 辨 识 度 的 品 牌 名 称 带 来 辨 识 度 ， 轻 松 为 你 的 造 型 增 添 摩 登 酷 感 魅 力 。 \n",
      "Target:\tdior （ 迪 奥 ） 这 款 遮 阳 帽 今 季 多 次 登 上 时 尚 杂 志 ， 成 为 品 牌 的 又 一 个 话 题 单 品 。 幻 彩 蓝 色 遮 挡 板 别 具 时 尚 玩 味 ， 配 以 具 辨 识 度 的 [UNK] j [UNK] adi ##or [UNK] 标 识 及 品 牌 标 志 ， 为 你 的 造 型 增 添 吸 睛 亮 点 。 \n",
      "Source:\t<unk> ##ba ##ng ##le 大 理 石 纹 over ##si ##ze 开 口 手 镯 \n",
      "Generated:\tj . cr ##ick ##et 这 款 手 镯 采 用 纯 棉 面 料 打 造 出 宽 松 廓 形 ， over ##si ##ze 版 型 带 来 随 性 自 然 感 觉 ， 是 打 造 摩 登 休 闲 造 型 的 理 想 单 品 。 \n",
      "Target:\tc ##ult ##ga ##ia 将 复 古 自 然 的 大 理 石 纹 融 入 这 款 开 口 手 镯 之 中 ， 并 以 红 色 设 计 搭 配 over ##si ##ze 廓 形 ， 轻 松 抓 人 眼 球 。 \n",
      "Source:\t两 件 外 层 内 翻 牛 仔 短 裤 拼 接 紧 身 裤 \n",
      "Generated:\talexander ##wang （ 亚 历 山 大 王 ） 这 款 短 裤 利 用 黑 色 面 料 打 造 出 略 微 宽 松 的 效 果 ， 令 你 的 运 动 造 型 更 具 酷 感 魅 力 。 \n",
      "Target:\tben ##ta ##ver ##ni ##ti ##un ##ra ##vel ##pro ##ject 这 款 单 品 由 牛 仔 短 裤 及 黑 色 紧 身 裤 构 成 ， 内 层 外 翻 设 计 玩 味 十 足 ， 彰 显 你 前 卫 过 人 的 摩 登 街 头 风 格 。 \n",
      "Source:\t##ic <unk> ##ad ##o 拼 色 围 边 荷 叶 边 <unk> 地 半 裙 \n",
      "Generated:\tne ##ed ##le & amp ; thread 这 款 半 裙 通 身 缀 有 金 色 亮 片 ， 远 一 看 ， 远 远 看 ， 远 看 ， 远 看 ， 让 你 的 造 型 轻 松 脱 颖 而 出 。 \n",
      "Target:\tma ##tic ##ev ##sk ##i 对 荷 叶 边 的 运 用 可 谓 得 心 应 手 。 这 款 半 裙 以 此 打 造 不 对 称 设 计 ， 白 色 围 边 令 层 次 及 廓 形 更 为 鲜 明 ， 助 你 轻 松 打 造 摩 登 迷 人 造 型 。 \n",
      "Source:\t##wo ##ol <unk> ##fo ##lk 立 领 短 款 混 羊 毛 针 织 衫 \n",
      "Generated:\tac ##nes ##tu ##dio ##s 这 款 针 织 衫 采 用 柔 软 舒 适 的 深 灰 色 设 计 ， over ##si ##ze 版 型 令 你 穿 着 倍 感 舒 适 。 不 妨 搭 配 浅 色 皮 裤 ， 打 造 个 性 休 闲 造 型 。 \n",
      "Target:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 与 w ##ool ##mark 联 乘 推 出 这 款 轻 柔 保 暖 的 立 领 混 羊 毛 针 织 衫 。 短 款 版 型 加 强 了 单 品 的 利 落 气 息 ， 轻 松 彰 显 你 摩 登 率 性 的 一 面 。 \n",
      "Source:\t<unk> 双 重 领 口 前 短 后 长 赛 车 主 题 t 恤 \n",
      "Generated:\tt ##ho ##mb ##row ##ne 这 款 深 蓝 色 t 恤 采 用 四 重 新 演 绎 设 计 ， 淡 淡 淡 光 泽 轻 松 提 升 单 品 的 设 计 感 ， 为 你 的 休 闲 造 型 注 入 几 分 女 人 味 。 \n",
      "Target:\tdr ##y ##cle ##ano ##n ##ly 这 款 t 恤 的 赛 车 主 题 印 花 及 黑 白 赛 结 <unk> 令 人 热 血 沸 腾 ， 前 短 后 长 版 型 、 双 重 领 口 及 蝙 蝠 袖 均 赋 予 了 单 品 摩 登 玩 味 ， 轻 松 彰 显 你 的 个 性 时 尚 态 度 。 \n",
      "Source:\t##wa ##ii 花 卉 印 花 over ##si ##ze 夹 棉 连 帽 夹 克 \n",
      "Generated:\tac ##nes ##tu ##dio ##s 这 款 连 帽 夹 克 以 over ##si ##ze 版 型 营 造 出 随 性 氛 围 ， over ##si ##ze 版 型 带 来 几 分 随 性 感 觉 ， 助 你 打 造 摩 登 休 闲 造 型 。 \n",
      "Target:\trichard ##q ##ui ##nn 擅 长 采 用 创 新 科 技 ， 来 创 造 华 丽 繁 复 、 炫 目 的 印 花 图 案 。 这 款 夹 棉 连 帽 夹 克 以 夸 张 的 over ##si ##ze 廓 形 吸 引 目 光 ， 通 身 点 缀 的 花 卉 印 花 鲜 艳 亮 眼 ， 助 你 在 人 群 中 突 围 而 出 。 \n",
      "Source:\t##ho ##ra 迷 你 穿 插 手 柄 真 皮 梯 形 水 桶 包 \n",
      "Generated:\tst ##au ##d 这 款 more ##au 水 桶 包 采 用 植 物 鞣 革 精 心 制 作 ， 简 洁 线 条 更 添 亮 眼 一 笔 ， 彰 显 你 的 时 尚 个 性 。 \n",
      "Target:\t设 计 师 carol ##ina ##san ##to ##dom ##ing ##o 曾 效 力 于 st ##au ##d ， 并 一 手 打 造 了 热 门 的 bi ##sse ##tt 水 桶 包 。 这 款 水 桶 包 来 自 主 打 简 洁 线 条 的 同 名 包 袋 品 牌 ， 以 小 牛 皮 裁 剪 出 简 洁 的 梯 形 轮 廓 ， 小 巧 <unk> <unk> 令 人 一 见 倾 心 。 \n",
      "Source:\t##co ##rn 儿 童 款 爱 心 刺 绣 徽 章 真 皮 运 动 鞋 \n",
      "Generated:\twin ##k 这 款 白 色 运 动 鞋 于 后 部 拼 接 了 同 色 真 皮 ， 为 小 朋 友 的 造 型 注 入 几 分 童 趣 。 \n",
      "Target:\twin ##k 以 三 颗 爱 心 刺 绣 徽 章 为 这 白 色 运 动 鞋 注 入 吸 睛 亮 点 ， 同 时 衬 托 出 小 朋 友 的 热 情 个 性 。 \n",
      "Source:\t##rl ##q ##ui ##n 人 造 珍 珠 及 仿 水 晶 吊 坠 耳 环 \n",
      "Generated:\tan ##ton ##he ##un ##is 这 款 耳 环 以 [UNK] go ##ing ##pl ##ace ##s [UNK] 字 样 增 添 玩 味 一 笔 ， 配 合 色 彩 缤 纷 的 仿 水 晶 点 缀 ， 为 你 的 造 型 注 入 几 分 年 轻 活 力 。 \n",
      "Target:\tan ##ton ##he ##un ##is 以 祖 母 绿 色 及 透 明 仿 水 晶 吊 坠 为 这 款 耳 环 注 入 复 古 色 彩 ， 结 合 圆 润 的 施 华 洛 世 奇 人 造 珍 珠 ， 让 你 的 造 型 轻 松 脱 颖 而 出 。 \n",
      "Source:\t<unk> ##g ##ra ##ff <unk> 小 号 涂 鸦 皱 感 真 皮 手 提 包 \n",
      "Generated:\tst ##ra ##th ##berry 这 款 east / west ##st ##y ##list 真 皮 手 拿 包 廓 形 小 巧 妙 ， 以 简 约 低 调 的 浅 粉 色 设 计 映 衬 品 牌 标 志 性 的 金 色 ， 演 绎 刚 柔 并 济 的 摩 登 美 学 。 \n",
      "Target:\tba ##len ##cia ##ga （ 巴 黎 世 家 ） 将 这 款 手 提 包 化 为 画 板 ， 以 涂 鸦 字 样 增 添 街 头 艺 术 色 彩 。 皱 感 真 皮 主 体 与 做 旧 感 金 属 细 节 营 造 出 复 古 氛 围 ， 彰 显 你 的 个 性 时 尚 魅 力 。 \n",
      "Source:\t##s - mo ##io ##ui 钻 石 18k 白 金 吊 坠 单 只 耳 环 \n",
      "Generated:\tof ##ee 的 设 计 充 满 简 约 优 雅 的 法 式 情 调 。 这 款 耳 环 采 用 18k 金 打 造 ， 简 洁 纤 细 的 链 条 随 风 摇 曳 摆 动 ， 让 你 的 造 型 于 举 手 投 足 间 展 现 灵 动 美 感 \n",
      "Target:\tof ##ee 的 名 字 灵 感 源 自 创 始 人 的 两 个 女 儿 f ##le ##ur 和 ch ##lo ##e ， 主 打 摩 登 简 洁 的 都 市 风 格 。 这 款 18k 白 金 耳 环 由 三 个 水 滴 状 缀 饰 组 合 而 成 ， 细 碎 钻 石 更 添 璀 璨 光 芒 ， 为 你 的 造 型 画 龙 点 睛 。 \n",
      "Source:\t##lo ##pe ##tte 儿 童 款 拼 色 条 纹 布 饰 吊 带 连 衣 裙 \n",
      "Generated:\tso ##nia ##ry ##ki ##el 这 款 连 衣 裙 以 拼 色 条 纹 及 波 点 营 造 鲜 明 色 彩 层 次 ， 助 小 朋 友 打 造 活 泼 可 爱 的 休 闲 造 型 。 \n",
      "Target:\tmon ##cle ##r （ 盟 可 睐 ） 以 拼 色 条 纹 布 饰 点 亮 这 款 灰 色 吊 带 连 衣 裙 ， 让 小 朋 友 轻 松 变 身 为 可 爱 文 艺 女 孩 。 \n",
      "Source:\t##u ##z 儿 童 款 品 牌 名 称 针 织 袜 靴 式 运 动 鞋 \n",
      "Generated:\twin ##k 这 款 运 动 鞋 采 用 针 织 面 料 打 造 出 对 比 色 彩 及 质 感 轻 盈 质 感 ， 两 侧 的 粉 色 设 计 甜 美 可 凸 显 你 的 纤 细 脚 部 ， 是 打 造 活 力 休 闲 造 型 的 理 想 \n",
      "Target:\tst ##ella ##mc ##car ##t ##ney （ 丝 黛 拉 麦 卡 妮 ） 以 缀 有 品 牌 名 称 缩 写 [UNK] st ##ella [UNK] 的 松 紧 带 为 这 款 粉 色 运 动 鞋 注 入 辨 识 度 ， 轻 松 展 现 小 朋 友 可 爱 活 泼 的 个 性 。 \n",
      "Source:\t##ona ##ld ##ro ##bert ##son ##lon ##nie 嘴 唇 印 花 真 丝 棒 球 夹 克 \n",
      "Generated:\t3 . 1 ##ph ##ill ##ip ##li ##m （ 菲 利 林 ） 这 款 棒 球 夹 克 利 用 拼 色 设 计 营 造 鲜 明 视 觉 变 化 ， 轻 松 为 你 的 休 闲 造 型 添 上 摩 登 一 笔 。 \n",
      "Target:\t社 交 网 络 红 人 <unk> ##ro <unk> ##son 凭 借 色 彩 缤 纷 的 艺 术 作 品 引 来 不 少 关 注 ， 与 alice + ol ##i ##via 的 活 泼 风 格 不 <unk> 而 合 。 这 款 真 丝 棒 球 夹 克 缀 有 抓 人 眼 球 的 嘴 唇 图 案 ， 为 你 的 活 力 造 型 注 入 时 尚 玩 味 。 \n",
      "Source:\t##og ##ram ##he ##art 流 苏 缀 饰 光 滑 小 牛 皮 心 形 斜 挎 包 \n",
      "Generated:\tst ##ra ##th ##berry 这 款 east / west ##st ##y ##list 真 皮 斜 挎 包 通 身 缀 满 金 色 金 属 杆 ， 带 来 几 分 摩 登 玩 味 。 \n",
      "Target:\tsaint ##la ##ure ##nt 这 款 斜 挎 包 采 用 光 滑 小 牛 皮 打 造 出 讨 喜 的 心 形 廓 形 ， 流 苏 缀 饰 更 添 玩 味 一 笔 。 配 合 充 满 辨 识 度 的 品 牌 名 称 标 志 ， 为 你 的 都 市 造 型 画 龙 点 睛 。 \n",
      "Source:\t##we ##ha <unk> <unk> <unk> ##ye ##t 百 褶 布 饰 拼 接 天 鹅 绒 露 踝 裤 \n",
      "Generated:\tne ##il ##bar ##re ##tt （ 尼 奥 贝 奈 特 ） 这 款 露 踝 裤 采 用 [UNK] 绸 面 料 制 作 ， 拼 接 的 黑 色 条 纹 为 单 品 增 添 玩 味 一 笔 ， 助 你 打 造 个 性 十 足 的 摩 登 造 型 。 \n",
      "Target:\trosie ##ass ##ou ##lin 这 款 天 鹅 绒 露 踝 裤 复 古 优 雅 ， 设 计 师 别 出 心 裁 地 于 裤 脚 口 背 面 拼 接 了 白 色 百 褶 布 饰 ， 为 单 品 注 入 层 次 惊 喜 。 \n",
      "Source:\t##pa ##is ##ley 不 对 称 衣 领 佩 斯 利 花 卉 透 视 薄 纱 上 衣 \n",
      "Generated:\tne ##il ##bar ##re ##tt （ 尼 奥 贝 奈 特 ） 这 款 黑 色 上 衣 采 用 [UNK] 绸 面 料 制 作 ， 左 侧 衣 袖 的 抽 褶 细 节 带 来 几 分 复 古 质 感 ， 助 你 打 造 别 具 一 格 的 都 市 造 型 。 \n",
      "Target:\t尽 <unk> see ##by ##ch ##lo ##e 今 季 的 服 饰 较 为 <unk> 向 现 代 都 市 格 调 ， 设 计 中 仍 可 见 波 西 米 亚 元 素 的 踪 影 。 这 款 透 视 薄 纱 上 衣 将 佩 斯 利 纹 和 花 卉 相 互 融 合 ， 不 对 称 衣 领 增 添 了 玩 味 一 笔 ， 是 性 感 雅 致 的 复 古 款 式 。 \n",
      "Source:\t##ls ##ne ##ak ##sm ##ini 儿 童 款 毛 球 点 缀 兔 子 造 型 闪 粉 运 动 鞋 \n",
      "Generated:\twin ##k 这 款 儿 童 款 运 动 鞋 以 掺 有 闪 粉 丝 线 的 毛 球 及 人 造 珍 珠 营 造 出 宛 若 可 爱 的 光 线 般 的 流 苏 ， 令 小 朋 友 的 造 型 更 具 活 泼 个 性 。 \n",
      "Target:\tmin ##nap ##ari ##kk ##a 这 款 兔 子 造 型 运 动 鞋 以 银 色 闪 粉 及 粉 色 细 节 碰 撞 出 甜 美 感 觉 ， 配 以 后 部 的 毛 球 装 饰 ， 助 小 朋 友 轻 松 打 造 闪 闪 惹 人 爱 的 可 爱 造 型 。 \n",
      "Source:\tmi ##lk ##sha ##ke ' st ##ra ##ss ##fl ##ora ##la ##pp ##li <unk> ##le ##ather ##ki ##ds ##sn ##ea <unk> ##s \n",
      "Generated:\tba ##len ##cia ##ga （ 巴 黎 世 家 ） 这 款 背 心 采 用 18k 金 制 造 ， 宛 若 折 射 出 光 线 的 蓝 色 彩 宛 若 一 样 晶 莹 夺 目 ， 令 人 一 见 倾 心 。 \n",
      "Target:\twin ##k <unk> <unk> <unk> ##pi <unk> ##fr ##om ##chi ##ld ##ren ' <unk> ##av ##our <unk> ##s ##we ##ett <unk> <unk> ##top <unk> ##ent ##the ##se ##mi <unk> ##sha ##ke ##ki ##ds <unk> ##ea <unk> ##s . this ##pa ##ir ##fe ##ature ##sa ##gle ##am ##ing ##ba ##nd ##wi ##th <unk> <unk> <unk> ##fl <unk> ##la ##pp ##li ##que ##to ##len ##dy ##our ##li ##tt ##le ##one ' s ##lo ##ok ##sa <unk> ##ek ##ys ##pa ##rk ##le . \n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(valid_iter):\n",
    "    src = batch.src.transpose(0, 1)[:1]\n",
    "    src = src.cuda()\n",
    "    src_mask = (src != SRC.vocab.stoi[\"<blank>\"]).unsqueeze(-2)\n",
    "    src_mask = src_mask.cuda()\n",
    "    out = greedy_decode(model, src, src_mask, \n",
    "                        max_len=60, start_symbol=TGT.vocab.stoi[\"<s>\"])\n",
    "    print(\"Source:\", end=\"\\t\")\n",
    "    for i in range(1, batch.src.size(0)):\n",
    "        sym = SRC.vocab.itos[batch.src.data[i, 0]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "    print(\"Generated:\", end=\"\\t\")\n",
    "    for i in range(1, out.size(1)):\n",
    "        sym = TGT.vocab.itos[out[0, i]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "    print(\"Target:\", end=\"\\t\")\n",
    "    for i in range(1, batch.trg.size(0)):\n",
    "        sym = TGT.vocab.itos[batch.trg.data[i, 0]]\n",
    "        if sym == \"</s>\": break\n",
    "        print(sym, end =\"\")\n",
    "    print()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
